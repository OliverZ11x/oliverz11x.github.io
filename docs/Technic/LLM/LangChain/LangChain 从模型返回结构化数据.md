---
title: LangChain ç»“æ„åŒ–æ•°æ®
date created: 2024/7/31 11:15
date modified: 2024/8/9 14:44
---
# LangChainä»æ¨¡å‹è¿”å›ç»“æ„åŒ–æ•°æ®

>[å¦‚ä½•ä»æ¨¡å‹è¿”å›ç»“æ„åŒ–æ•°æ® | ğŸ¦œï¸ğŸ”— LangChain](https://python.langchain.com/v0.2/docs/how_to/structured_output/#using-pydanticoutputparser)

è®©æ¨¡å‹è¿”å›ç¬¦åˆç‰¹å®šæ¨¡å¼çš„è¾“å‡ºé€šå¸¸å¾ˆæœ‰ç”¨ã€‚ä¸€ä¸ªå¸¸è§çš„ç”¨ä¾‹æ˜¯ä»æ–‡æœ¬ä¸­æå–æ•°æ®ä»¥æ’å…¥æ•°æ®åº“æˆ–ç”¨äºå…¶ä»–ä¸‹æ¸¸ç³»ç»Ÿã€‚æœ¬æŒ‡å—ä»‹ç»äº†ä»æ¨¡å‹è·å–ç»“æ„åŒ–è¾“å‡ºçš„å‡ ç§ç­–ç•¥ã€‚

## .with_structured_output() æ–¹æ³•

----------------------------

è¿™æ˜¯è·å–ç»“æ„åŒ–è¾“å‡ºçš„æœ€ç®€å•ã€æœ€å¯é çš„æ–¹æ³•ã€‚.with_structured_output() æ˜¯ä¸ºé‚£äº›æä¾›äº†ç”¨äºç»“æ„åŒ–è¾“å‡ºçš„æœ¬åœ° APIï¼ˆå¦‚å·¥å…· / å‡½æ•°è°ƒç”¨æˆ– JSON æ¨¡å¼ï¼‰çš„æ¨¡å‹è€Œå®ç°çš„ï¼Œå¹¶åœ¨å¼•æ“ç›–ä¸‹åˆ©ç”¨äº†è¿™äº›åŠŸèƒ½ã€‚

è¯¥æ–¹æ³•å°†æ¨¡å¼ä½œä¸ºè¾“å…¥ï¼Œæ¨¡å¼æŒ‡å®šäº†æ‰€éœ€è¾“å‡ºå±æ€§çš„åç§°ã€ç±»å‹å’Œæè¿°ã€‚è¯¥æ–¹æ³•ä¼šè¿”å›ä¸€ä¸ªç±»ä¼¼æ¨¡å‹çš„ Runnableï¼Œä½†è¾“å‡ºçš„ä¸æ˜¯å­—ç¬¦ä¸²æˆ–ä¿¡æ¯ï¼Œè€Œæ˜¯ä¸ç»™å®šæ¨¡å¼ç›¸å¯¹åº”çš„å¯¹è±¡ã€‚æ¨¡å¼å¯ä»¥æŒ‡å®šä¸º JSON æ¨¡å¼æˆ– Pydantic ç±»ã€‚å¦‚æœä½¿ç”¨ JSON æ¨¡å¼ï¼ŒRunnable å°†è¿”å›ä¸€ä¸ªå­—å…¸ï¼›å¦‚æœä½¿ç”¨ Pydantic ç±»ï¼Œåˆ™å°†è¿”å› Pydantic å¯¹è±¡ã€‚

ä¸¾ä¸ªä¾‹å­ï¼Œè®©æˆ‘ä»¬ç”¨ä¸€ä¸ªæ¨¡å‹æ¥ç”Ÿæˆä¸€ä¸ªç¬‘è¯ï¼Œå¹¶å°†ç¬‘ç‚¹å’Œç¬‘æ–™åˆ†å¼€ï¼š

```python
import getpass
import os

os.environ["OPENAI_API_KEY"] = getpass.getpass()
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(model="gpt-3.5-turbo-0125")
```

å¦‚æœæˆ‘ä»¬å¸Œæœ›æ¨¡å‹è¿”å›ä¸€ä¸ª Pydantic å¯¹è±¡ï¼Œåªéœ€ä¼ å…¥æ‰€éœ€çš„ Pydantic ç±»å³å¯ï¼š

```python
from typing import Optional
from langchain_core.pydantic_v1 import BaseModel, Field

class Joke(BaseModel):
    """Joke to tell user."""
    setup: str = Field(description="The setup of the joke")
    punchline: str = Field(description="The punchline to the joke")
    rating: Optional[int] = Field(description="How funny the joke is, from 1 to 10")

structured_llm = llm.with_structured_output(Joke)
structured_llm.invoke("Tell me a joke about cats")
```

```python
Joke(setup='Why was the cat sitting on the computer?', punchline='Because it wanted to keep an eye on the mouse!', rating=8)
```

æç¤º

é™¤äº† Pydantic ç±»çš„ç»“æ„ä¹‹å¤–ï¼ŒPydantic ç±»çš„åç§°ã€docstring ä»¥åŠå‚æ•°çš„åç§°å’Œæä¾›çš„æè¿°ä¹Ÿéå¸¸é‡è¦ã€‚å¤§éƒ¨åˆ†æƒ…å†µä¸‹ï¼Œwith_structured_output ä½¿ç”¨çš„æ˜¯æ¨¡å‹çš„å‡½æ•° / å·¥å…·è°ƒç”¨ APIï¼Œå› æ­¤å¯ä»¥æœ‰æ•ˆåœ°å°†æ‰€æœ‰è¿™äº›ä¿¡æ¯è§†ä¸ºæ·»åŠ åˆ°äº†æ¨¡å‹æç¤ºä¸­ã€‚

å¦‚æœæ‚¨ä¸æƒ³ä½¿ç”¨ Pydanticï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä¼ å…¥ä¸€ä¸ª JSON Schema dictã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå“åº”ä¹Ÿæ˜¯ä¸€ä¸ª dictï¼š

```python
json_schema = {
    "title": "joke",
    "description": "Joke to tell user.",
    "type": "object",
    "properties": {
        "setup": {
            "type": "string",
            "description": "The setup of the joke",
        },
        "punchline": {
            "type": "string",
            "description": "The punchline to the joke",
        },
        "rating": {
            "type": "integer",
            "description": "How funny the joke is, from 1 to 10",
        },
    },
    "required": ["setup", "punchline"],
}

structured_llm = llm.with_structured_output(json_schema)
structured_llm.invoke("Tell me a joke about cats")
```

```python
{'setup': 'Why was the cat sitting on the computer?',
 'punchline': 'Because it wanted to keep an eye on the mouse!',
 'rating': 8}


```

### åœ¨å¤šä¸ªæ¨¡å¼ä¹‹é—´è¿›è¡Œé€‰æ‹©

è®©æ¨¡å‹ä»å¤šä¸ªæ¨¡å¼ä¸­è¿›è¡Œé€‰æ‹©çš„æœ€ç®€å•æ–¹æ³•æ˜¯åˆ›å»ºä¸€ä¸ªå…·æœ‰ Union ç±»å‹å±æ€§çš„çˆ¶ Pydantic ç±»ï¼š

```python
from typing import Union

class ConversationalResponse(BaseModel):
    """Respond in a conversational manner. Be kind and helpful."""
    response: str = Field(description="A conversational response to the user's query")


class Response(BaseModel):
    output: Union[Joke, ConversationalResponse]

structured_llm = llm.with_structured_output(Response)
structured_llm.invoke("Tell me a joke about cats")
```

```python
Response(output=Joke(setup='Why was the cat sitting on the computer?', punchline='To keep an eye on the mouse!', rating=8))
```

```python
structured_llm.invoke("How are you today?")
```

```python
Response(output=ConversationalResponse(response="I'm just a digital assistant, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?"))
```

å¦å¤–ï¼Œå¦‚æœæ‚¨é€‰æ‹©çš„æ¨¡å‹æ”¯æŒå·¥å…·è°ƒç”¨ï¼Œæ‚¨ä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨å·¥å…·è°ƒç”¨ï¼Œè®©æ¨¡å‹åœ¨é€‰é¡¹ä¹‹é—´è¿›è¡Œé€‰æ‹©ã€‚è¿™éœ€è¦è¿›è¡Œæ›´å¤šçš„è§£æå’Œè®¾ç½®ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹ä¼šå¸¦æ¥æ›´å¥½çš„æ€§èƒ½ï¼Œå› ä¸ºæ‚¨ä¸å¿…ä½¿ç”¨åµŒå¥—æ¨¡å¼ã€‚æ›´å¤šè¯¦æƒ…ï¼Œè¯·å‚é˜…æœ¬æ“ä½œæŒ‡å—ã€‚

### æµ

å½“è¾“å‡ºç±»å‹ä¸º dict æ—¶ï¼ˆå³æ¨¡å¼æŒ‡å®šä¸º JSON Schema dict æ—¶ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹ç»“æ„åŒ–æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œæµå¼å¤„ç†ã€‚

```python
structured_llm = llm.with_structured_output(json_schema)

for chunk in structured_llm.stream("Tell me a joke about cats"):
    print(chunk)
```

```python
{}
{'setup': ''}
{'setup': 'Why'}
{'setup': 'Why was'}
{'setup': 'Why was the'}
{'setup': 'Why was the cat'}
{'setup': 'Why was the cat sitting'}
{'setup': 'Why was the cat sitting on'}
{'setup': 'Why was the cat sitting on the'}
{'setup': 'Why was the cat sitting on the computer'}
{'setup': 'Why was the cat sitting on the computer?'}
{'setup': 'Why was the cat sitting on the computer?', 'punchline': ''}
{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because'}
{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it'}
{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted'}
{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to'}
{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep'}
{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an'}
{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye'}
{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on'}
{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the'}
{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse'}
{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse!'}
{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse!', 'rating': 8}
```

### å°‘é‡æç¤º

å¯¹äºæ›´å¤æ‚çš„æ¨¡å¼ï¼Œåœ¨æç¤ºä¸­æ·»åŠ å°‘é‡ç¤ºä¾‹éå¸¸æœ‰ç”¨ã€‚æœ‰å‡ ç§æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ã€‚

æœ€ç®€å•ã€æœ€æ™®éçš„æ–¹æ³•æ˜¯åœ¨æç¤ºä¸­çš„ç³»ç»Ÿä¿¡æ¯ä¸­æ·»åŠ ç¤ºä¾‹ï¼š

```python
from langchain_core.prompts import ChatPromptTemplate

system = """You are a hilarious comedian. Your specialty is knock-knock jokes. \
Return a joke which has the setup (the response to "Who's there?") and the final punchline (the response to "<setup> who?").

Here are some examples of jokes:

example_user: Tell me a joke about planes
example_assistant: {{"setup": "Why don't planes ever get tired?", "punchline": "Because they have rest wings!", "rating": 2}}

example_user: Tell me another joke about planes
example_assistant: {{"setup": "Cargo", "punchline": "Cargo 'vroom vroom', but planes go 'zoom zoom'!", "rating": 10}}

example_user: Now about caterpillars
example_assistant: {{"setup": "Caterpillar", "punchline": "Caterpillar really slow, but watch me turn into a butterfly and steal the show!", "rating": 5}}"""

prompt = ChatPromptTemplate.from_messages([("system", system), ("human", "{input}")])

few_shot_structured_llm = prompt | structured_llm
few_shot_structured_llm.invoke("what's something funny about woodpeckers")
```

API å‚è€ƒï¼šèŠå¤©æç¤ºæ¨¡æ¿

```python
{'setup': 'Woodpecker',
 'punchline': "Woodpecker goes 'knock knock', but don't worry, they never expect you to answer the door!",
 'rating': 8}
```

å½“ç»“æ„åŒ–è¾“å‡ºçš„åŸºæœ¬æ–¹æ³•æ˜¯å·¥å…·è°ƒç”¨æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å°†ç¤ºä¾‹ä½œä¸ºæ˜¾å¼å·¥å…·è°ƒç”¨ä¼ å…¥ã€‚æ‚¨å¯ä»¥æŸ¥çœ‹æ‰€ä½¿ç”¨çš„æ¨¡å‹æ˜¯å¦åœ¨å…¶ API å‚è€ƒä¸­ä½¿ç”¨äº†å·¥å…·è°ƒç”¨ã€‚

```python
from langchain_core.messages import AIMessage, HumanMessage, ToolMessage

examples = [
    HumanMessage("Tell me a joke about planes", ),
    AIMessage(
        "",
        ,
        tool_calls=[
            {
                "name": "joke",
                "args": {
                    "setup": "Why don't planes ever get tired?",
                    "punchline": "Because they have rest wings!",
                    "rating": 2,
                },
                "id": "1",
            }
        ],
    ),
    
    ToolMessage("", tool_call_id="1"),
        
    HumanMessage("Tell me another joke about planes", ),
    AIMessage(
        "",
        ,
        tool_calls=[
            {
                "name": "joke",
                "args": {
                    "setup": "Cargo",
                    "punchline": "Cargo 'vroom vroom', but planes go 'zoom zoom'!",
                    "rating": 10,
                },
                "id": "2",
            }
        ],
    ),
    ToolMessage("", tool_call_id="2"),
    HumanMessage("Now about caterpillars", ),
    AIMessage(
        "",
        tool_calls=[
            {
                "name": "joke",
                "args": {
                    "setup": "Caterpillar",
                    "punchline": "Caterpillar really slow, but watch me turn into a butterfly and steal the show!",
                    "rating": 5,
                },
                "id": "3",
            }
        ],
    ),
    ToolMessage("", tool_call_id="3"),
]
system = """You are a hilarious comedian. Your specialty is knock-knock jokes. \
Return a joke which has the setup (the response to "Who's there?") \
and the final punchline (the response to "<setup> who?")."""

prompt = ChatPromptTemplate.from_messages(
    [("system", system), ("placeholder", "{examples}"), ("human", "{input}")]
)
few_shot_structured_llm = prompt | structured_llm
few_shot_structured_llm.invoke({"input": "crocodiles", "examples": examples})
```

API å‚è€ƒï¼šAIMessage | HumanMessage | ToolMessage

```python
{'setup': 'Crocodile',
 'punchline': "Crocodile 'see you later', but in a while, it becomes an alligator!",
 'rating': 7}
```

æœ‰å…³ä½¿ç”¨å·¥å…·è°ƒç”¨æ—¶å°‘æ•°é•œå¤´æç¤ºçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…æ­¤å¤„ã€‚

### (é«˜çº§ï¼‰æŒ‡å®šç»“æ„åŒ–è¾“å‡ºçš„æ–¹æ³•

å¯¹äºæ”¯æŒä¸€ç§ä»¥ä¸Šè¾“å‡ºç»“æ„åŒ–æ–¹æ³•çš„æ¨¡å‹ï¼ˆå³åŒæ—¶æ”¯æŒå·¥å…·è°ƒç”¨å’Œ JSON æ¨¡å¼ï¼‰ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ method= å‚æ•°æŒ‡å®šè¦ä½¿ç”¨çš„æ–¹æ³•ã€‚

JSON æ¨¡å¼

å¦‚æœä½¿ç”¨ JSON æ¨¡å¼ï¼Œä»éœ€åœ¨æ¨¡å‹æç¤ºä¸­æŒ‡å®šæ‰€éœ€çš„æ¨¡å¼ã€‚ä¼ é€’ç»™ with_structured_output çš„æ¨¡å¼å°†ä»…ç”¨äºè§£ææ¨¡å‹è¾“å‡ºï¼Œè€Œä¸ä¼šåƒå·¥å…·è°ƒç”¨é‚£æ ·ä¼ é€’ç»™æ¨¡å‹ã€‚

è¦æŸ¥çœ‹æ‚¨ä½¿ç”¨çš„æ¨¡å‹æ˜¯å¦æ”¯æŒ JSON æ¨¡å¼ï¼Œè¯·æŸ¥çœ‹ API å‚è€ƒä¸­çš„ç›¸å…³æ¡ç›®ã€‚

```python
structured_llm = llm.with_structured_output(Joke, method="json_mode")

structured_llm.invoke(
    "Tell me a joke about cats, respond in JSON with `setup` and `punchline` keys"
)
```

```python
Joke(setup='Why was the cat sitting on the computer?', punchline='Because it wanted to keep an eye on the mouse!', rating=None)
```

### (é«˜çº§ï¼‰åŸå§‹è¾“å‡º

LLM åœ¨ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºæ–¹é¢å¹¶ä¸å®Œç¾ï¼Œå°¤å…¶æ˜¯å½“æ¨¡å¼å˜å¾—å¤æ‚æ—¶ã€‚é€šè¿‡ include_raw=Trueï¼Œå¯ä»¥é¿å…å¼•å‘å¼‚å¸¸å¹¶è‡ªè¡Œå¤„ç†åŸå§‹è¾“å‡ºã€‚è¿™å°†æ”¹å˜è¾“å‡ºæ ¼å¼ï¼Œä½¿å…¶åŒ…å«åŸå§‹ä¿¡æ¯è¾“å‡ºã€è§£æå€¼ï¼ˆå¦‚æœæˆåŠŸï¼‰ä»¥åŠä»»ä½•ç”±æ­¤äº§ç”Ÿçš„é”™è¯¯ï¼š

```python
structured_llm = llm.with_structured_output(Joke, include_raw=True)

structured_llm.invoke(
    "Tell me a joke about cats, respond in JSON with `setup` and `punchline` keys"
)
```

```python
{'raw': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ASK4EmZeZ69Fi3p554Mb4rWy', 'function': {'arguments': '{"setup":"Why was the cat sitting on the computer?","punchline":"Because it wanted to keep an eye on the mouse!"}', 'name': 'Joke'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 107, 'total_tokens': 143}, 'model_name': 'gpt-4-0125-preview', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6491d35b-9164-4656-b75c-d7882cfb76cb-0', tool_calls=[{'name': 'Joke', 'args': {'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse!'}, 'id': 'call_ASK4EmZeZ69Fi3p554Mb4rWy'}], usage_metadata={'input_tokens': 107, 'output_tokens': 36, 'total_tokens': 143}),
 'parsed': Joke(setup='Why was the cat sitting on the computer?', punchline='Because it wanted to keep an eye on the mouse!', rating=None),
 'parsing_error': None}
```

## ç›´æ¥æç¤ºå’Œè§£ææ¨¡å‹è¾“å‡º

-----------

å¹¶éæ‰€æœ‰æ¨¡å‹éƒ½æ”¯æŒ .with_structured_output()ï¼Œå› ä¸ºå¹¶éæ‰€æœ‰æ¨¡å‹éƒ½æ”¯æŒå·¥å…·è°ƒç”¨æˆ– JSON æ¨¡å¼ã€‚å¯¹äºè¿™ç±»æ¨¡å‹ï¼Œä½ éœ€è¦ç›´æ¥æç¤ºæ¨¡å‹ä½¿ç”¨ç‰¹å®šæ ¼å¼ï¼Œå¹¶ä½¿ç”¨è¾“å‡ºè§£æå™¨ä»åŸå§‹æ¨¡å‹è¾“å‡ºä¸­æå–ç»“æ„åŒ–å“åº”ã€‚

### ä½¿ç”¨ Pydantic è¾“å‡ºè§£æå™¨

ä¸‹é¢çš„ç¤ºä¾‹ä½¿ç”¨å†…ç½®çš„ PydanticOutputParser æ¥è§£æèŠå¤©æ¨¡å‹çš„è¾“å‡ºï¼Œæç¤ºå…¶ä¸ç»™å®šçš„ Pydantic æ¨¡å¼ç›¸åŒ¹é…ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬æ˜¯ä»è§£æå™¨çš„ä¸€ä¸ªæ–¹æ³•ä¸­ç›´æ¥å‘æç¤ºæ·»åŠ æ ¼å¼æŒ‡ä»¤çš„ï¼š

```python
from typing import List

from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field


class Person(BaseModel):
    """Information about a person."""

    name: str = Field(..., description="The name of the person")
    height_in_meters: float = Field(
        ..., description="The height of the person expressed in meters."
    )


class People(BaseModel):
    """Identifying information about all people in a text."""

    people: List[Person]

parser = PydanticOutputParser(pydantic_object=People)

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "Answer the user query. Wrap the output in `json` tags\n{format_instructions}",
        ),
        ("human", "{query}"),
    ]
).partial(format_instructions=parser.get_format_instructions())
```

API å‚è€ƒï¼šPydanticOutputParser | ChatPromptTemplate

è®©æˆ‘ä»¬æ¥çœ‹çœ‹æœ‰å“ªäº›ä¿¡æ¯ä¼šè¢«å‘é€åˆ°æ¨¡å‹ä¸­ï¼š

```python
query = "Anna is 23 years old and she is 6 feet tall"

print(prompt.invoke(query).to_string())
```

```python
System: Answer the user query. Wrap the output in `json` tags
The output should be formatted as a JSON instance that conforms to the JSON schema below.

As an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}
the object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.

Here is the output schema:
```

{"æè¿°"ï¼š "è¯†åˆ«æ–‡æœ¬ä¸­æ‰€æœ‰äººç‰©çš„ä¿¡æ¯"ï¼Œ"å±æ€§"ï¼š {"äººç‰©"ï¼š {"æ ‡é¢˜"ï¼š "äººç‰©", "type"ï¼š "array", "items"ï¼š {"$ref"ï¼š "#/definitions/Person"}}}, "required"ï¼š ["äººå‘˜"]ï¼Œ"å®šä¹‰"ï¼š {"äºº"ï¼š {"æ ‡é¢˜"ï¼š "äºº"ï¼Œ"æè¿°"ï¼š å…³äºä¸€ä¸ªäººçš„ä¿¡æ¯ "ï¼Œ" ç±»å‹ "ï¼š" å¯¹è±¡ "ï¼Œ" å±æ€§ "ï¼š" å±æ€§ "ï¼š" ä¿¡æ¯ "ï¼š" å¯¹è±¡ "ï¼Œ" å±æ€§ "ï¼š {" åç§° "ï¼š {" æ ‡é¢˜ "ï¼š" å§“å "ï¼Œ" æè¿° "ï¼š" äººçš„å§“å "ï¼Œ" ç±»å‹ "ï¼š"string"ï¼ˆå­—ç¬¦ä¸²ï¼‰},"height_in_meters"ï¼š {" æ ‡é¢˜ "ï¼š" ä»¥ç±³ä¸ºå•ä½çš„èº«é«˜ "ï¼Œ" æè¿° "ï¼š" ä»¥ç±³ä¸ºå•ä½çš„èº«é«˜ "ï¼Œ" ç±»å‹ "ï¼š" æ•°å­— "}}ï¼š" æ•°å­— "}}ï¼Œ" å¿…å¡« "ï¼š ["name","height_in_meters"]}}}

```python
Human: Anna is 23 years old and she is 6 feet tall
```

ç°åœ¨è®©æˆ‘ä»¬è°ƒç”¨å®ƒï¼š

```python
chain = prompt | llm | parser

chain.invoke({"query": query})
```

```python
People(people=[Person(name='Anna', height_in_meters=1.8288)])
```

å¦‚éœ€æ·±å…¥äº†è§£å¦‚ä½•ä½¿ç”¨è¾“å‡ºè§£æå™¨å’Œæç¤ºæŠ€æœ¯è¿›è¡Œç»“æ„åŒ–è¾“å‡ºï¼Œè¯·å‚é˜…æœ¬æŒ‡å—ã€‚

### è‡ªå®šä¹‰è§£æ

æ‚¨è¿˜å¯ä»¥ä½¿ç”¨ LangChain è¡¨è¾¾å¼è¯­è¨€ï¼ˆLCELï¼‰åˆ›å»ºè‡ªå®šä¹‰æç¤ºå’Œè§£æå™¨ï¼Œä½¿ç”¨æ™®é€šå‡½æ•°è§£ææ¨¡å‹è¾“å‡ºï¼š

```python
import json
import re
from typing import List

from langchain_core.messages import AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field

class Person(BaseModel):
    """Information about a person."""

    name: str = Field(..., description="The name of the person")
    height_in_meters: float = Field(
        ..., description="The height of the person expressed in meters."
    )


class People(BaseModel):
    """Identifying information about all people in a text."""

    people: List[Person]



prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "Answer the user query. Output your answer as JSON that  "
            "matches the given schema: ```json\n{schema}\n```. "
            "Make sure to wrap the answer in ```json and ``` tags",
        ),
        ("human", "{query}"),
    ]
).partial(schema=People.schema())



def extract_json(message: AIMessage) -> List[dict]:
    """Extracts JSON content from a string where JSON is embedded between ```json and ``` tags.

    Parameters:
        text (str): The text containing the JSON content.

    Returns:
        list: A list of extracted JSON strings.
    """
    text = message.content
    
    pattern = r"```json(.*?)```"

    
    matches = re.findall(pattern, text, re.DOTALL)

    
    try:
        return [json.loads(match.strip()) for match in matches]
    except Exception:
        raise ValueError(f"Failed to parse: {message}")
```

API å‚è€ƒï¼šAIMessage | ChatPromptTemplate

ä¸‹é¢æ˜¯å‘é€ç»™æ¨¡å‹çš„æç¤ºï¼š

```python
query = "Anna is 23 years old and she is 6 feet tall"

print(prompt.format_prompt(query=query).to_string())
```

```python
System: Answer the user query. Output your answer as JSON that  matches the given schema: ```json
{'title': 'People', 'description': 'Identifying information about all people in a text.', 'type': 'object', 'properties': {'people': {'title': 'People', 'type': 'array', 'items': {'$ref': '#/definitions/Person'}}}, 'required': ['people'], 'definitions': {'Person': {'title': 'Person', 'description': 'Information about a person.', 'type': 'object', 'properties': {'name': {'title': 'Name', 'description': 'The name of the person', 'type': 'string'}, 'height_in_meters': {'title': 'Height In Meters', 'description': 'The height of the person expressed in meters.', 'type': 'number'}}, 'required': ['name', 'height_in_meters']}}}
```. Make sure to wrap the answer in ```json and ``` tags
Human: Anna is 23 years old and she is 6 feet tall
```

ä¸‹é¢æ˜¯æˆ‘ä»¬è°ƒç”¨å®ƒæ—¶çš„æ ·å­ï¼š

```python
chain = prompt | llm | extract_json

chain.invoke({"query": query})
```

```python
[{'people': [{'name': 'Anna', 'height_in_meters': 1.8288}]}]
```

## é£é™©

å½“æ¨¡å‹ç»“æ„åŒ–è¾“å‡ºæ–¹æ³•åº”ç”¨äºAgentç±»å‹æ•°æ®æ—¶
- langchain_coreåº“æ„å»ºçš„æ¨¡å‹ç»“æ„åŒ–è¾“å‡ºæ–¹æ³•(with_structured_output)ç¼ºå°‘bind_toolså±æ€§ï¼Œæ— æ³•é€‚é…Langgraphåº“æ„å»ºçš„react_agentã€‚è¿™ä¸€é—®é¢˜é™åˆ¶äº†SQLAgentçš„åŠŸèƒ½å’Œåº”ç”¨èŒƒå›´ã€‚
- ç»“æ„åŒ–è¾“å‡ºæ¨¡å—çš„è®¾è®¡éœ€è¦æ›´é«˜çš„çµæ´»æ€§ï¼Œä»¥åº”å¯¹å¤æ‚æŸ¥è¯¢ç»“æœçš„å¤šæ ·æ€§å’Œä¸ç¡®å®šæ€§ã€‚éœ€è¦è¿›ä¸€æ­¥æ‰©å±•å’Œä¼˜åŒ–pydanticæ¨¡å‹ï¼Œæå‡å…¶é€‚ç”¨æ€§ã€‚
- ç ”ç©¶å¹¶è§£å†³langchain_coreåº“ä¸Langgraphåº“ä¹‹é—´çš„å…¼å®¹æ€§é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯bind_toolså±æ€§ç¼ºå¤±çš„é—®é¢˜ã€‚å°è¯•æ‰¾åˆ°æ›¿ä»£æ–¹æ¡ˆæˆ–è¿›è¡Œåº“çš„è°ƒæ•´ï¼Œä»¥ç¡®ä¿SQLAgentçš„åŠŸèƒ½å®Œæ•´æ€§ã€‚

---
