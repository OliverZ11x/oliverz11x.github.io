---
date created: 2024/8/29 15:41
date modified: 2024/8/29 15:45
---
## 文本清洗概述

在舆情分析和情感分析的任务中，文本数据通常包含大量的噪声信息，例如HTML标签、特殊字符、多余的空格、无关标记等。因此，对文本进行清洗是确保分类模型性能的重要步骤。以下是基于你的代码总结的文本清洗流程。

### 文本清洗步骤

#### 移除HTML标签

   - 使用正则表达式 `<.*?>` 匹配并移除文本中的HTML标签，保持文本的纯净。

   ```python
   def remove_html_tags(text):
       clean = re.compile('<.*?>')
       return re.sub(clean, '', text)
   ```

#### 移除特殊字符

   - 保留字母、数字和中文字符，去除所有其他特殊字符。这一步能有效清理文本中不必要的符号和标点。

   ```python
   def remove_special_characters(text):
       text = re.sub(r'[^a-zA-Z0-9\u4e00-\u9fa5\s]', '', text)
       return text
   ```

#### 去除多余空格

   - 使用正则表达式匹配多个连续的空格，并将其替换为单个空格，同时移除文本首尾的空格。

   ```python
   def remove_extra_spaces(text):
       return re.sub(r'\s+', ' ', text).strip()
   ```

#### 清除标签和标记

   - 去除文本中的特定标记（如`#标签`、`@用户`等），避免这些噪声干扰模型的分类。

   ```python
   def clean_tag(text):
       clean_text = re.sub(r'#.*? ', '', text)
       clean_text = re.sub(r'@.*? ', '', clean_text)
       clean_text = re.sub(r'#\w+', '', clean_text)
       clean_text = re.sub(r'@\w+', '', clean_text)
       return clean_text
   ```

#### 移除特定字符和短语

   - 进一步清除文本中特定的短语或标记，如“车友圈广场”，以确保内容的纯净性。

   ```python
   def remove_specific_characters_regex(text):
       text = re.sub('车友圈广场 ', '', text)
       text = re.sub('车友圈广场', '', text)
       return text
   ```

#### 综合清洗函数

   - 以上步骤可以综合为一个清洗函数，依次执行各个清洗步骤，确保文本数据的高质量。

   ```python
   def clean_text(text):
       text = clean_tag(text)
       text = remove_specific_characters_regex(text)
       text = remove_extra_spaces(text)
       return text
   ```

### 文本清洗后的处理步骤

#### 处理缺失值

   - 将缺失值填充为空字符串，并将文本数据类型转换为字符串类型，确保后续处理的兼容性。

   ```python
   saic_data['内文'] = saic_data['内文'].fillna('').astype(str)
   ```

#### 文本清洗应用

   - 使用`clean_text`函数对数据进行清洗，移除噪声信息。

   ```python
   saic_data['清洗后内文'] = saic_data['内文'].apply(clean_text)
   ```

#### 文本分割

   - 将清洗后的文本按照标点符号进行分句，生成单独的句子列表，以便后续分析。

   ```python
   essays = saic_data['清洗后内文'].tolist()
   single_sentences_list = []
   for essay in essays:
       single_sentences_list.extend(re.split(r'(?<=[。?？!！])', essay))
   ```

#### 句子过滤

   - 过滤掉空文本和长度不合适的句子（长度小于3或大于200），确保数据的有效性。
   - 进一步过滤掉非中文文本和包含广告的句子。

   ```python
   filtered_sentences_len = [sentence for sentence in single_sentences_list if 3 <= len(sentence) < 200]
   filtered_sentences_NoneAD = [sentence for sentence in filtered_sentences_len if '广告' not in sentence]
   filtered_sentences_CN = [sentence for sentence in filtered_sentences_NoneAD if chinese_pattern.search(sentence)]
   ```

#### 结果保存与可视化

   - 将清洗和分割后的句子保存为文本文件，并对句子长度分布进行可视化，以便进一步分析和处理。

   ```python
   with open('filtered_sentences_CN.txt', 'w', encoding='utf-8') as file:
       for sentence in filtered_sentences_CN:
           file.write(sentence + '\n')

   sentence_lengths = [len(sentence) for sentence in filtered_sentences_CN]
   plt.hist(sentence_lengths, bins=500)
   plt.xlabel('Sentence Length')
   plt.ylabel('Frequency')
   plt.title('Length Distribution of Sentences')
   plt.show()
   ```

![[IMG-2024-08-29-15-44-54.png]]
