---
date created: 2025/7/11 10:29
date modified: 2025/7/12 13:2
---
- **通用模型**：`http://172.32.1.163:8000/v1` `http://gpu3.xmcloud.local:8000/v1
- **涉台专用模型**：`http://172.32.1.162:8000/v1` `http://gpu2.xmcloud.local:8000/v1`
- **涉藏专用模型**：`http://172.32.1.161:8000/v1` `http://gpu1.xmcloud.local:8000/v1`

## 马上消费

## 数据清洗

### 数据清洗遇到重复的内容的话，如何进行处理？

我通常会先按重复类型分类处理。完全重复我会用哈希值或数据库去重；轻微变化重复会先做文本标准化再去重；语义重复则用向量相似度模型，比如 SentenceBERT，对文本做语义去重。

|重复类型|处理方法|工具/技术|
|---|---|---|
|**完全重复**|去重（哈希值、唯一性约束、MD5/sha256）|Pandas、数据库去重、Bloom Filter|
|**轻微变化重复**|标准化后去重（统一标点、去空格、去噪声）|正则、文本标准化、NLP 清洗工具|
|**语义重复**|相似度去重（向量相似度、文本相似度、Embedding）|SentenceBERT、Faiss、ANN 检索|

### 数据清洗遇到相同的实体，如何处理

在数据清洗中遇到相同或相似的实体，我一般先做实体消歧和对齐，常用的方法包括字典映射、正则匹配、向量相似度对齐、知识库对齐等。确认是同一实体后，会选择一个标准化名称，通常依据数据源权威性、出现频率、语义清晰度等标准来统一。

在我的情报分析项目中，我就用过向量相似度和规则方法结合，解决了组织名、地名等实体的标准化问题，提升了数据一致性和分析准确性。

### 模型微调如何确定数据量和轮次

- 小数据量（<1 万）：通常 5-10 轮（避免过拟合）；
- 中等数据量（1 万 - 10 万）：通常 10-30 轮；
- 大数据量（>10 万）：通常 30-100 轮（需依赖早停，避免无效迭代）。