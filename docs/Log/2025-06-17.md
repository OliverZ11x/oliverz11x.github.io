---
date created: 2025/6/17 9:39
date modified: 2025/6/17 15:56
---
1. 闭源数据，对模型的翻译质量进行优化和调整。
2. 调整和限制模型的 CPU 使用率，制定具体核心数。
3. 模型备案，评估测试题及结果（补充总表和评估类型）


`vllm serve Qwen/Qwen3-1.7B --chat-template /mnt/workspace/chat_template.jinja --api-key token-abc123 --dtype float16 --max-num-seqs 512 --port 9000 ​--trust-remote-code Ture --model "/mnt"`

`vllm serve /mnt --host 0.0.0.0 --port 8000 --api-key token-abc123 --chat-template /mnt/chat_template.jinja`

import requests ``import json`` ``# Endpoint URL`` url = "http://localhost:8000/v1/chat/completions"``   `` # Headers ``headers = {`    `"Content-Type": "application/json",``}``# Payload`` payload = {`    `"messages": [`        `{"role": "system", "content": "You are a helpful assistant."},`        `{"role": "user", "content": "Tell about Bitcoin."},`    `], `    `"model": "Qwen/Qwen-7B-Chat", `    `"stream": False, `    `"max_tokens": 2048, `    `"stop": None, `    `"frequency_penalty": 0, `    `"presence_penalty": 0, `    `"temperature": 0.6, `    `"top_p": 0.90 ``}`` # Make the request ``response = requests.post(url, headers=headers, data=json.dumps(payload))`` # Extracting 'content' value from response ``result = response.json()`` content = result['choices'][0]['message']['content']``print(content)