---
date created: 2025/2/17 9:38
date modified: 2025/2/17 11:44

### **数据处理部分PPT内容**

---
#### **1. 数据读取**

- **数据来源**：
  - 数据来自两个文件夹：`MQU-CBP/radial`（桡动脉压数据）和 `MQU-CBP/aortic`（中心动脉压数据）。
  - 每个文件夹包含132个文件，每个文件对应一个受试者的血压数据。
- **数据读取步骤**：
  1. 使用 `os.listdir` 列出文件夹中的所有文件。
  2. 逐个读取文件内容，并将数据存储为浮点数列表。
  3. 最终得到两个列表：
	 - `x1`：132个受试者的桡动脉压数据，形状为 `[132, 1409]`。
	 - `y1`：132个受试者的中心动脉压数据，形状为 `[132, 1409]`。
- **代码展示**：

  ```python
  # 读取桡动脉压数据
  filename1 = []
  rootdir = '.\\MQU-CBP\\radial'
  list = os.listdir(rootdir)
  for i in range(0, len(list)):
      path = os.path.join(rootdir, list[i])
      filename1.append(path)

  x1 = []
  for i in range(0, len(filename1)):
      with open(filename1[i]) as file_object1:
          lines1 = file_object1.readlines()
      file1 = []
      for line in lines1:
          row1 = line.split()
          file1.append(float(row1[0]))
      x1.append(file1)
  ```

---

#### **2. 数据集划分**

- **训练集与测试集划分**：
  - 将132个受试者的数据划分为训练集和测试集。
  - 训练集：前120个受试者的数据。
  - 测试集：后12个受试者的数据。
- **代码展示**：

  ```python
  train_x1 = x1[0:120]  # 前120个人的桡动脉压
  train_y1 = y1[0:120]  # 前120个人的中心动脉压

  text_x1 = x1[120:]    # 后12个人的桡动脉压
  text_y1 = y1[120:]    # 后12个人的中心动脉压
  ```

---

#### **3. 数据增强**

- **数据增强目的**：
  - 增加数据多样性，防止模型过拟合。
  - 通过随机截取数据段，生成更多的训练样本。
- **数据增强步骤**：
  1. 对每个受试者的数据，随机截取500个采样点的时间段。
  2. 每个受试者的数据生成10个增强样本。
  3. 最终得到：
	 - 训练集：1100个增强样本（120个受试者 × 10个样本）。
	 - 测试集：120个增强样本（12个受试者 × 10个样本）。
- **代码展示**：

  ```python
  train_x2 = []
  train_y2 = []
  for c in range(len(train_x1)):
      if len(train_x1[c]) > 550:
          for d in range(10):
              head1 = random.randint(0, len(train_x1[c]) - 700)
              train_x2.append(train_x1[c][head1+100:head1+600])
              train_y2.append(train_y1[c][head1+100:head1+600])
  ```

---

#### **4. 数据归一化**

- **归一化目的**：
  - 将数据缩放到相同的尺度，避免某些特征对模型训练产生过大影响。
  - 采用均值归一化：(x - 均值) / 标准差。
- **归一化步骤**：
  1. 对训练集和测试集分别进行归一化。
  2. 计算每个数据集的均值和标准差，并进行归一化处理。
  3. 最终得到归一化后的数据，形状为 `[1100, 500, 1]`（训练集）和 `[120, 500, 1]`（测试集）。

- **代码展示**：

  ```python
  # 训练集归一化
  train_x3, rap_mean_all_train, rap_varience_all_train = NormalizationMeanVariance(train_x2)
  train_y3, cap_mean_all_train, cap_varience_all_train = NormalizationMeanVariance(train_y2)

  # 测试集归一化
  text_x3, rap_mean_all_test, rap_varience_all_test = NormalizationMeanVariance(text_x2)
  text_y3, cap_mean_all_test, cap_varience_all_test = NormalizationMeanVariance(text_y2)

  # 数据reshape
  train_x = np.array(train_x3).reshape(1100, 500, 1)
  train_y = np.array(train_y3).reshape(1100, 500, 1)
  text_x = np.array(text_x3).reshape(-1, 500, 1)
  text_y = np.array(text_y3).reshape(-1, 500, 1)
  ```

---

#### **5. 数据处理结果**

- **数据形状**：
  - 训练集：`train_x` 和 `train_y` 的形状为 `[1100, 500, 1]`。
  - 测试集：`text_x` 和 `text_y` 的形状为 `[120, 500, 1]`。
- **归一化效果**：
  - 归一化后的数据均值为0，标准差为1，确保了数据在同一尺度上。
- **可视化展示**：
  - 可以展示归一化前后的数据对比图，说明归一化对数据分布的影响。

---

#### **6. 总结**

- **数据处理流程**：
  1. 数据读取：从文件中读取桡动脉压和中心动脉压数据。
  2. 数据集划分：将数据划分为训练集和测试集。
  3. 数据增强：通过随机截取数据段，增加数据多样性。
  4. 数据归一化：对数据进行均值归一化，确保数据在同一尺度上。

- **数据处理的意义**：
  - 通过数据增强和归一化，提升了模型的泛化能力和训练效率。

---

### **PPT设计建议**

1. **图表展示**：
   - 展示数据读取、数据增强、归一化的流程图。
   - 展示归一化前后的数据分布对比图。

2. **代码片段**：
   - 在PPT中嵌入关键代码片段，帮助观众理解数据处理的具体实现。

3. **数据形状展示**：
   - 使用表格展示数据形状的变化（如从 `[132, 1409]` 到 `[1100, 500, 1]`）。

4. **总结页**：
   - 用简洁的语言总结数据处理的关键步骤和意义。

---

你的模型创新点介绍和代码看起来非常清晰且结构合理，接下来我会帮助你更详细地梳理和表达这个内容，使其能够更好地在中期答辩中呈现。你可以参考以下思路：

---

### 模型创新点介绍

#### 1. **模型背景与目标**

本研究的核心任务是使用深度学习模型重构中心动脉压信号（Central Arterial Pressure, CAP）。通过传统方法的不足，我们提出了一种结合 **U-Net** 与 **Bi-LSTM** 网络结构的创新模型，称为 **EUNet-CAP**。该模型能够更好地捕捉血压信号中的周期性和时序特征，提高中心动脉压信号的重构精度。

#### 2. **创新点概述**

我们的模型设计主要包括以下创新点：

- **U-Net 结构的应用**：利用卷积层提取局部特征，通过并行的卷积层对输入信号进行局部模式的学习（如收缩压和舒张压）。
- **双向 LSTM（Bi-LSTM）**：在网络后端使用双向 LSTM 网络进行全局依赖建模。双向 LSTM 能够同时捕捉来自未来和过去的上下文信息，进一步增强对信号全局特征的理解。
- **全连接层的重构能力**：通过全连接层将提取到的特征映射回中心动脉压信号，从而实现信号的精确重构。

#### 3. **U-Net + Bi-LSTM结构的优势**

- **卷积层**：每个通道输入信号通过卷积操作提取局部特征，尤其适合血压信号这类具有周期性和局部特征的数据。
- **Bi-LSTM层**：采用双向LSTM层对时间序列信号进行建模，能够捕捉信号中的长时间依赖关系和未来的上下文信息，提升对复杂时序数据的预测精度。
- **端到端重构**：通过一个全连接层，将LSTM提取的全局特征映射到最终的中心动脉压信号，提供端到端的信号重构能力。

---

### 代码结构与解释

#### 1. **卷积层（`Conv1D_Block`）**

在这个模块中，我们使用了一维卷积层（`Conv1D`）来提取局部特征。每个通道的输入信号通过一个卷积块进行处理，这些卷积块能够捕捉血压信号的局部模式，如周期性的波峰和波谷。

```python
class Conv1D_Block(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride):
        super(Conv1D_Block, self).__init__()
        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, stride)
        self.bn = nn.BatchNorm1d(out_channels)
        self.activation = nn.SELU()

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.activation(x)
        return x
```

- **卷积操作**：使用`Conv1d`提取局部特征，能够有效捕捉信号中的短期变化。
- **批量归一化（BatchNorm）**：提高模型训练的稳定性，加速收敛过程。
- **激活函数**：使用SELU激活函数，能够增强模型的非线性表达能力。

#### 2. **Bi-LSTM层（`BiLSTM`）**

Bi-LSTM是该模型的核心部分，通过双向LSTM对序列数据进行建模，能够同时学习过去和未来的上下文信息，提高对血压信号的理解。

```python
class EUNetCAP_Model(nn.Module):
    def __init__(self, configs):
        super(EUNetCAP_Model, self).__init__()
        self.bilstm = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, batch_first=True, bidirectional=True)
```

- **双向LSTM**：`bidirectional=True`使得LSTM能够通过双向传递信息，捕捉到血压信号中的复杂时序依赖。
- **隐藏层大小**：设置为128，能够有效处理复杂的时序数据。

#### 3. **全连接层（`fc`）**

最终，我们通过全连接层将LSTM输出的特征映射到血压信号的重构空间，从而输出预测结果。

```python
self.fc = nn.Linear(128 * 2, self.pred_len)  # 双向LSTM输出大小为2倍的隐藏层大小
```

- **全连接层**：将LSTM提取的时序特征进行线性变换，最终输出中心动脉压信号的预测值。

#### 4. **模型前向传播过程（`forward`）**

在模型的前向传播过程中，信号经过卷积层提取局部特征后，通过Bi-LSTM层进行全局依赖建模，最后通过全连接层进行信号重构。

```python
def forward(self, x):
    x = x.permute(0, 2, 1)  # 调整输入形状
    conv_outputs = []
    for i in range(self.channels):
        conv_output = self.conv_blocks[i](x[:, i:i+1, :])  # 逐通道处理
        conv_outputs.append(conv_output)
    x = torch.cat(conv_outputs, dim=1)  # 合并卷积输出
    x, _ = self.bilstm(x.permute(0, 2, 1))  # 双向LSTM处理
    x = x[:, -1, :]  # 取最后时间步
    x = self.fc(x)  # 预测重构信号
    return x
```

- **数据处理**：输入数据首先通过`permute`函数调整形状，确保卷积层能够按通道对每个信号进行处理。
- **局部特征提取**：每个信号通过卷积层提取局部特征。
- **全局特征建模**：通过Bi-LSTM处理局部特征，捕捉时序信息。
- **信号重构**：最后，通过全连接层输出预测的中心动脉压信号。

---

### 训练与评估

- **训练策略**：采用交叉验证方法来评估模型性能，确保模型能够适应不同的训练和测试数据集。
- **数据增强**：通过数据增强技术扩充训练集，提升模型的泛化能力，避免过拟合。

### 总结

该模型结合了U-Net的局部特征提取和Bi-LSTM的全局依赖建模，成功地提升了中心动脉压信号的重构精度。通过卷积层捕捉信号中的局部模式，并使用双向LSTM来捕捉复杂的时序关系，该模型能够准确地预测中心动脉压信号的波形，为相关医学领域的诊断提供有力支持。

---

这样你可以通过简明扼要的方式来介绍模型的创新点和代码实现，在答辩时更加清晰地展示你的研究成果。

对于你的PPT内容和代码部分，以下是我对模型介绍和迁移学习代码流程的解释：

### 1. **模型介绍与迁移学习**

**背景：** 该部分的核心目标是解决数据稀缺问题，特别是在中心动脉血压（CAP）信号重构中，利用迁移学习（Transfer Learning）技术进行模型增强。迁移学习可以将源领域（如大规模的数据集）中学到的知识迁移到目标领域（如小规模的数据集），从而提升模型在数据稀缺情况下的表现。

**创新点：**

- **基于模型迁移的迁移学习策略：** 在源数据集上进行预训练，并将学到的特征迁移到目标数据集上，进行微调，从而提高重构精度。
- **跨模态数据迁移：** 利用不同模态的数据源（如PPG信号与桡动脉血压波形），增强模型的特征学习能力。
- **数据预处理方法：** 针对模拟和真实数据集，提出了新的预处理方法，以促进模型训练的高效性，特别是在跨模态数据训练的情况下。

### 2. **模型代码解析**

这个模型的结构结合了卷积神经网络（CNN）、双向长短时记忆网络（BiLSTM）、自注意力机制（Self-Attention）以及全连接层，用于处理中心动脉血压信号的重构任务。

#### **代码结构：**

- **输入层与卷积层：**

	```python
    self.conv1_1 = keras.layers.Conv1D(filters, kernel_size, padding='same', name='conv1_1')
    self.conv1_2 = keras.layers.Conv1D(filters, kernel_size, padding='same', name='conv1_2')
    self.conv1_3 = keras.layers.Conv1D(filters, kernel_size, padding='same', name='conv1_3')
    ```

	通过多个卷积层（`Conv1D`）提取信号的特征，利用卷积核（`filters`）和卷积窗口大小（`kernel_size`）在时间序列上滑动进行特征学习。每个卷积层后接ReLU激活函数（`Activation("relu")`），以增加非线性特征。


- **双向LSTM层：**

	```python
    self.bilstm1 = keras.layers.Bidirectional(keras.layers.LSTM(units=hider_size, input_shape=(batch,500,filters*2), recurrent_initializer='glorot_uniform', return_sequences=True, dropout=0.1, name='BiLSTM'))
    ```

	使用双向LSTM网络（`Bidirectional`），使得模型可以利用序列的前后上下文信息。LSTM是一种能够处理时间序列数据的循环神经网络（RNN），能够捕捉信号中的时序信息。这里的`units`表示隐藏层的神经元数目。


- **自注意力层：**

	```python
    self.SeqSelfAttention_1 = SeqSelfAttention(kernel_regularizer=regularizers.l2(1e-4), bias_regularizer=regularizers.l1(1e-4), attention_regularizer_weight=1e-4, attention_activation='sigmoid', name='Attention_1')
    self.SeqSelfAttention_2 = SeqSelfAttention(kernel_regularizer=regularizers.l2(1e-4), bias_regularizer=regularizers.l1(1e-4), attention_regularizer_weight=1e-4, attention_activation='sigmoid', name='Attention_2')
    ```

	自注意力机制（Self-Attention）可以让模型在计算时关注序列中各个位置的重要性，从而捕捉长期依赖信息。这里通过两个注意力层提升序列表示能力。


- **全连接层（Dense Layer）：**

	```python
    self.fc = keras.layers.Dense(1, name='FC')
    ```

	最后，通过全连接层（`Dense`）对特征进行整合，输出最终的重构结果。`Dense(1)`表示输出是一个标量（重构后的血压信号值）。

#### **模型的工作流程：**

1. **卷积层提取特征：** 从输入的原始血压信号中提取低层特征。
2. **双向LSTM捕捉时序信息：** 利用LSTM捕捉信号中的时间依赖性，学习输入序列的时序特征。
3. **自注意力层优化表示：** 通过自注意力机制，进一步强化模型对序列各部分重要性的关注。
4. **全连接层输出预测值：** 最终通过全连接层得到血压信号的预测结果。

#### **迁移学习与模型训练：**

在训练过程中，我们首先在源数据集（大规模数据集）上预训练模型，然后将预训练的权重迁移到目标数据集（小规模数据集）上，并进行微调。通过这种方式，迁移学习能够提高模型在小规模数据集上的表现，减少数据稀缺带来的影响。

```python
model = CBiMSAN2(hider_size=60, filters=50, kernel_size=3, batch=50)
model.build(input_shape=(None, 500, 1))
model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='mse')
history = model.fit(train_x, train_y, batch_size=64, epochs=50, validation_split=0.1)
```

- 这里使用Adam优化器和均方误差（MSE）作为损失函数进行训练。
- `train_x`和`train_y`是训练数据，`validation_split=0.1`表示将10%的数据用于验证。

**训练结果评估：**

```python
bo_mae, bofeng_rmse, bofeng_mae, bogu_rmse, bogu_mae, R = evaluate(model=model, text_x=text_x, text_y=text_y, cap_mean_all_test=cap_mean_all_test, cap_varience_all_test=cap_varience_all_test, baocun=-1)
```

- 使用`evaluate`函数对模型进行评估，计算各种指标，如MAE（平均绝对误差）和RMSE（均方根误差）。

最终，模型权重保存为`yuxunlian.tf`，以便后续加载和推断。

### 3. **PPT中解释建议**

在PPT中，您可以按以下结构呈现模型代码和迁移学习的流程：

1. **介绍迁移学习的背景**：如何通过迁移学习解决数据稀缺问题，提升模型性能。
2. **模型架构图**：绘制模型的结构图，包括卷积层、LSTM层、注意力机制和全连接层。
3. **代码流程**：
	- 说明每个层的功能（如卷积提取特征、BiLSTM学习时序依赖、自注意力机制强化特征表示等）。
	- 解释迁移学习如何通过预训练和微调提升模型在小数据集上的效果。
4. **训练与评估**：展示模型训练的代码及结果，强调评估指标（如MAE、RMSE等）对模型性能的衡量。

这样，你的PPT内容将会更具条理，并能清晰地解释模型及其应用。