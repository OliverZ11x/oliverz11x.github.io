---
date created: 2025/3/27 9:50
date modified: 2025/7/18 16:53
---
# Qwen-14B-instruct 基座模型微调

## 一、项目概述

### 1.1 背景与目标

基于阿里巴巴通义大模型 Qwen-14B-instruct 进行微调，旨在提升模型在特定领域上的表现，生成更高质量的回答和指令跟随文本。通过结合 LoRA 技术和 PEFT 微调方法，实现模型性能增强。

### 1.2 技术栈与工具

- **基座模型**：Qwen-14B-instruct
- **数据处理工具**：unstructured 库（用于 PDF、DOC 和 DOCX 文档解析与清洗）
- **数据生成**：xchat4t（用于生成问答和指令跟随数据集）
- **微调框架**：PEFT + LoRA
- **硬件环境**：H100 GPU

---

## 二、数据处理与生成

### 2.1 数据来源与解析

原始语料来源于多种格式的文档，包括 PDF、DOC 和 DOCX 文件。使用 `unstructured` 库对文档进行解析和清洗，保留文本内容并去除冗余信息。

**处理流程：**

1. 使用 `unstructured` 库读取文档内容；
2. 去除格式标签、页眉页脚、特殊字符等；
3. 清理空白行、多余换行符；
4. 合并段落，保持上下文连贯性。

### 2.2 数据生成

使用 xchat4t 对清洗后的文本生成问答对和指令跟随数据集。

**生成方式：**

- **生成任务类型**：
	- 问答对生成
	- 文本摘要生成
	- 指令跟随生成
- **数据格式示例：**

```json
    {
        "context": "[20200901为噩梦做准备：台湾海峡的战备和临时联合行动(翻译).docx] 台湾的国防预算可能不能完全反映其实际的国防支出水平。包括军事养恤金、国防装备特别预算、国防基础设施和准军事部队预算等在内的许多项目已经列入中央政府预算的其他部分。此外，税收减少和经济波动也加剧了国防支出的保守性。\n\n近年来，台湾逐步增加了国防预算。2020财年的国防预算相比2019财年增长了5.16%，而同期国内生产总值的增长也突显了台湾政府对国防的重视。此外，F-16V战斗机的采购也显著增加了国防预算。 \n\n国防开支、经济增长和社会福利支出之间的平衡一直是一个争议点。适当的国防开支可以促进经济增长，在地方一级创造就业机会和收入。而对高成本的硬件投资和维持先进战备状态的需要，也推动了国防预算的增长。\n\n台湾面临的战备挑战较大，但近20年来台湾在改革其武装部队方面取得了重要进展，并逐步稳固了其民主政体。有鉴于此，台湾的国防预算分配十分关键，涵盖了人员、运营和军事投资三大类。尽管面临着资源分配的挑战，但政府的支出保守态度以及对经济和社会福利其他方面的投资需求，使得国防预算的平衡成为必要。\n\n台湾军事的人力资源是一大挑战，自1990年代以来进行的一系列军事改革旨在优化武装部队的结构，从主要依赖义务兵役的大军向一支更精简、全志愿的部队转型。预备役制度的调整和后备部队的动员能力是国防战略中的关键部分。",

        "input": "台湾的国防预算分配需要考虑哪些主要因素，以及这些因素如何影响国防预算的划分?",

        "output": "# 台湾海峡的战备和临时联合行动分析报告\n\n## 一、政策背景与目标\n\n近年来，台湾不断增加国防预算，反映出其对于加强自身军力和战备状态的紧迫意图。特别是2020财年国防预算较2019年增长了5.16%，显示了其对提高军事现代化和战备能力的持续重视。台湾政府通过购买F-16V战斗机等先进装备，旨在应对与中国大陆可能的军事对抗和地区安全压力。\n\n## 二、政策影响与风险评估\n\n台湾提升军事预算深化了其军事战略从传统的义务兵役向全志愿兵力转变，这使得其军队更加专业和技术化。同时，提高国防支出有助于台湾经济增长，比如通过军事采购活动推动相关产业的发展。然而，增加国防预算也使得政府在社会福利和经济发展其他领域的投资面临压力，这在长远中可能影响民众对政府的支持。\n\n## 三、涉我性分析\n\n台湾的国防预算增长直接挑战了中国的国家安全与领土完整。台湾通过引进更多先进武器系统和提高快速反应能力，其显著的反华意图和应对大陆可能军事压力的准备，使台湾成为潜在的冲突火点。这种军事策略的转变可能会推动台湾进一步从中国大陆政治影响中独立出来，加深两岸的不信任和对峙。\n\n## 四、事件发展趋势预测\n\n预计台湾将继续增加其国防预算，并进一步强化与美国等西方国家的军事合作，来应对增加的地区不安全感。此外，台湾可能会继续推进军事现代化，包括网络战和信息战的能力提升，以准备不对称战争的可能性。\n\n## 五、案例与事实支撑\n\n根据《Jane’s Defence Weekly》的报告，台湾在2020年进行的多项军事演习，展示了其在提高快速部署和多军种协同作战能力方面取得的进展。此外，台湾与美国的军事交流增加，包括F-16V战斗机的交付和升级，进一步强化了台湾的空中战力。\n\n## 六、反制措施与应对建议\n\n1. **政治方面**：加强与台湾存在共同利益的国家的外交关系，特别是在国际组织中的合作，以压制台湾的国际空间。\n2. **军事方面**：通过不断提升解放军在海空联合作战能力，确保在台湾海峡的军事优势。\n3. **经济方面**：利用对台经贸手段，如限制对台敏感技术和关键原料的出口，以影响台湾经济情况。\n4. **舆论信息战**：加强对台湾内部矛盾和问题的宣传，以减少其社会对政府军事行为的支持。\n\n## 七、趋势与情报价值评估\n\n短期内，台湾的军事化趋势及其与西方国家的军事合作将继续增加，对中国构成更大的安全挑战。中长期来看，通过实施上述反制措施，并继续加强我军建设和现代化，可有效遏制台湾的军事野心，并维护区域稳定。情报价值在于提供中国对台政策的调整与战略决策的支持。"
    }
```

---

## 三、模型微调过程

### 3.1 微调方法与代码实现

采用 **LoRA（Low-Rank Adaptation）** 技术进行模型微调，通过对部分参数进行低秩分解，减少显存消耗。

**代码关键部分：**

- 使用 PEFT 库加载 Qwen-14B-instruct 模型；
- 启用 LoRA 适配器；
- 将微调数据集加载至模型中；
- 启动训练过程。

**核心代码示例：**

#### 数据集

```python
def process_func(example):
    # 定义固定的instruction
    INSTRUCTION = """
    ### **任务描述：**
    你的任务是基于给定文本与用户问题，生成一份**政治情报分析报告**。  
    报告需从**中国情报人员立场**出发，针对事件进行**涉我性分析与发展趋势预测**，并提供**具体可操作的反制措施与情报评估**。
    ---
    ### **生成规则**
    #### **报告结构**
    - **标题**：明确事件主题，使用简洁且具有情报指向性的标题。
    - **一、政策背景与目标**
        - 事件发生的背景与敌方意图。
    - **二、政策影响与风险评估**
        - 涉及政治、经济、军事、外交、舆论等多维度影响。
    - **三、涉我性分析**
        - 从**中国视角出发**，研判事件对我国的政治、军事、经济、外交与社会影响。
        - 明确**敌方反华意图**，分析前因后果与具体影响。
    - **四、事件发展趋势预测**
        - 基于**历史案例、情报信息与事件逻辑**，预测相关国家下一步举措。
        - 引用**时事新闻信息与案例**作为支撑，增强时效性与可信度。
    - **五、案例与事实支撑**
        - 引用**权威数据、案例与时事信息**，确保分析有据可依。
    - **六、反制措施与应对建议**
        - 提出**政治、军事、外交、经贸、舆论**多维度反制方案。
        - 方案需具体且可操作，落到实处。
    - **七、趋势与情报价值评估**
        - 预判事件的**短期与中长期走向**。
        - 分析情报价值与对后续工作的影响。
    """
    MAX_LENGTH = 2048    # Llama分词器会将一个中文字切分为多个token，因此需要放开一些最大长度，保证数据的完整性
    input_ids, attention_mask, labels = [], [], []
    instruction = tokenizer(f"<|im_start|>system\n{INSTRUCTION}<|im_end|>\n<|im_start|>user\n{example['input']}<|im_end|>\n<|im_start|>assistant\n", add_special_tokens=False)  # add_special_tokens 不在开头加 special_tokens
    response = tokenizer(f"{example['output']}", add_special_tokens=False)
    input_ids = instruction["input_ids"] + response["input_ids"] + [tokenizer.pad_token_id]
    attention_mask = instruction["attention_mask"] + response["attention_mask"] + [1]  # 因为eos token咱们也是要关注的所以 补充为1
    labels = [-100] * len(instruction["input_ids"]) + response["input_ids"] + [tokenizer.pad_token_id]  
    if len(input_ids) > MAX_LENGTH:  # 做一个截断
        input_ids = input_ids[:MAX_LENGTH]
        attention_mask = attention_mask[:MAX_LENGTH]
        labels = labels[:MAX_LENGTH]
    return {
        "input_ids": input_ids,
        "attention_mask": attention_mask,
        "labels": labels
    }
    
tokenized_id = ds.map(process_func, remove_columns=ds.column_names)
```

#### 模型训练

```python
from peft import LoraConfig, get_peft_model, TaskType
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer

# 加载模型和tokenizer
model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen1.5-14B-Chat", device_map="auto")
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen1.5-14B-Chat")

# LoRA配置
config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
    r=8,                    # LoRA秩
    lora_alpha=32,          # LoRA缩放因子
    lora_dropout=0.1,       # Dropout比例
)
model = get_peft_model(model, config)

# 加载数据集并训练
trainer = Trainer(
    model=model,
    args=TrainingArguments(
	    output_dir="./output_taiwan/Qwen2.5_instruct_14B_lora_gernerate",
	    per_device_train_batch_size=4,
	    gradient_accumulation_steps=4,
	    logging_steps=10,
	    num_train_epochs=3,
	    save_steps=100,
	    learning_rate=1e-4,
	    save_on_each_node=True,
	    gradient_checkpointing=True,
	    warmup_ratio=0.1,
    ),
    train_dataset=tokenized_id,
    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),
trainer.train()
```

### 3.2 超参数设置

- **学习率**：1e-4
- **批次大小**：4（H100）
- **LoRA秩**：8
- **微调轮数**：3
- **最大序列长度**：2048
- **优化器**：AdamW

### 3.3 训练

1. 将生成的数据集划分为训练、验证和测试集；
2. 使用 LoRA 对模型进行微调；
3. 验证集评估，检查过拟合情况；
4. 保存微调后的模型权重。

---

## 四、实验结果与评估

### 4.1 评估指标

- **F1-score**：是模型生成回答的准确性评估指标，主要适用于问答任务。它是精确率和召回率的调和平均值。

| 指标       | 基座模型 | 微调模型 |
| -------- | ---- | ---- |
| F1-score | 0.83 | 0.88 |

### 4.2 实验结果

![[IMG-2025-07-18-16-52-56.png]]
