---
date created: 2025/5/18 22:32
date modified: 2025/5/19 0:57
---
# 第一部分：总叙述

本次评估严格依据《生成式人工智能服务管理暂行办法》（以下简称《办法》）展开。《办法》明确要求生成式人工智能服务提供者需对训练数据来源、真实性负责，确保数据合法、合规、有效。在数据安全方面，要求建立健全数据安全管理制度，采取必要技术措施保障数据安全；在算法安全方面，强调需定期审核、评估、验证生成式人工智能服务的安全性、准确性、稳定性。此外，《办法》对服务提供者的内容管理责任进行明确规定，要求建立健全内容审核机制，防范生成、传播虚假信息和违法信息。

同时，评估参照《生成式人工智能服务安全基本要求》（GB/T 42574—2023），该标准从数据安全、算法安全、服务安全、安全管理等维度，对生成式人工智能服务提出具体要求。例如，在数据安全领域，规定训练数据需进行去重、去毒等预处理，保障数据质量；在算法安全方面，要求对算法进行可解释性、公平性、鲁棒性等评估，防止算法偏见和安全漏洞。

除上述文件外，评估还引用多项国家标准与行业规范。在网络安全方面，参照《信息安全技术 网络安全等级保护基本要求》（GB/T 22239—2019），对企业网络架构、访问控制、安全审计等进行评估，确保网络环境安全可靠。在个人信息保护领域，依据《个人信息保护法》《信息安全技术 个人信息安全规范》（GB/T 35273—2020），对企业个人信息收集、存储、使用、共享等环节进行审查，保障用户个人信息安全。此外，在数据传输安全方面，引用《信息安全技术 数据传输安全技术要求》（GB/T 35274—2023），对数据传输过程中的加密、认证等技术措施进行评估。

本次评估范围覆盖重庆埃克斯曼得信息技术有限公司 Xm-phi 大语言模型全生命周期，具体包括：

1. **数据处理环节**：涵盖训练数据的采集、存储、清洗、标注、使用等过程，评估数据来源合法性、数据质量、数据安全保护措施等。
2. **算法研发环节**：对模型算法的设计、开发、训练、优化等过程进行评估，重点审查算法的安全性、可解释性、公平性、鲁棒性等指标。
3. **服务部署环节**：对模型的部署环境，包括服务器、网络设备、云服务平台等进行评估，检查网络安全防护、访问控制、数据传输安全等措施的落实情况。
4. **安全管理环节**：评估企业安全管理制度的完善性，包括组织架构、人员管理、安全事件应急响应机制等；审查安全管理措施的执行情况，确保企业安全管理体系有效运行。

# 第二部分：相关管理制度

## 一、组织架构深度剖析

### （一）部门职责划分

重庆埃克斯曼得信息技术有限公司围绕生成式人工智能服务安全管理，构建了层次分明、职责清晰的组织架构。公司设立人工智能研发部、数据安全部、信息安全部、合规管理部四大核心部门，协同保障 Xm-phi 大语言模型全生命周期安全。

人工智能研发部负责大语言模型的算法设计、开发与优化，需严格遵循《生成式人工智能服务安全基本要求》中关于算法可解释性、鲁棒性的规定，确保模型技术架构安全可靠。同时，承担模型训练过程中的数据需求分析与技术对接工作，与数据安全部紧密协作，保障训练数据的质量与安全性。

数据安全部主要承担数据全流程管理职责。在数据采集环节，依据《个人信息保护法》和《数据安全法》要求，严格审核数据来源合法性；在数据存储阶段，落实加密存储、定期备份等措施，防止数据泄露与丢失；在数据处理方面，负责执行数据去重、去毒等清洗工作，确保进入模型训练的数据符合安全标准。

信息安全部专注于网络安全与系统安全防护。通过部署防火墙、入侵检测系统、漏洞扫描工具等设备，实时监测网络环境安全状况，及时发现并处理网络攻击和安全漏洞；对服务器、云服务平台等基础设施进行安全配置与维护，保障模型服务稳定运行；同时，负责制定和实施信息安全应急预案，提升企业应对突发安全事件的能力。

合规管理部负责对企业运营活动进行法律合规审查。对照《生成式人工智能服务管理暂行办法》等法律法规，定期审核企业安全管理制度、数据处理活动、服务内容等是否符合要求；组织开展内部合规培训，提高全体员工的法律意识和合规操作能力；在外部沟通中，及时跟进政策法规变化，确保企业始终保持合法合规运营状态。

### （二）岗位设置明细

公司针对各核心部门设置了专业化岗位，明确岗位职责与分工：

1. **人工智能研发部**：设有 NLP 算法工程师、模型训练工程师、算法测试工程师等岗位。NLP 算法工程师负责大语言模型算法设计与优化，需具备深厚的自然语言处理理论基础和编程能力；模型训练工程师专注于数据预处理、模型训练与调优工作，确保模型训练过程高效、准确；算法测试工程师则负责对模型进行功能测试、安全测试，发现并反馈算法潜在问题。
2. **数据安全部**：包括数据采集专员、数据清洗工程师、数据存储管理员等岗位。数据采集专员负责合法合规采集数据，与数据提供方签订相关协议；数据清洗工程师运用专业技术和工具，对采集数据进行去重、去毒处理；数据存储管理员负责管理数据存储系统，保障数据存储安全与高效访问。
3. **信息安全部**：涵盖网络安全工程师、系统安全工程师、安全运维工程师等岗位。网络安全工程师负责网络安全防护体系建设与维护，抵御外部网络攻击；系统安全工程师专注于服务器、操作系统等的安全配置与漏洞修复；安全运维工程师则负责日常安全监测、日志分析与应急响应支持工作。
4. **合规管理部**：设有合规专员、法务顾问等岗位。合规专员负责日常合规检查与监督，协助各部门完善合规流程；法务顾问则为企业提供专业法律意见，处理法律纠纷与合规风险评估工作。

## 二、安全人员体系

### （一）人员能力评估

公司建立了完善的人员能力评估体系，定期对安全人员进行考核，确保团队能力满足工作需求。能力评估分为理论知识考核、实操技能测试和工作业绩评价三部分。

理论知识考核每季度开展一次，内容涵盖《生成式人工智能服务安全基本要求》《个人信息保护法》等法律法规，以及人工智能、数据安全、网络安全等专业技术知识。通过笔试形式，检验员工对理论知识的掌握程度。

实操技能测试每半年进行一次，根据不同岗位设置针对性考核内容。例如，NLP 算法工程师需完成算法优化、模型调优实操任务；网络安全工程师需模拟网络攻击与防御场景，展示漏洞修复与应急响应能力。通过实操测试，评估员工实际工作技能水平。

工作业绩评价以年度为周期，结合员工日常工作表现、项目完成情况、安全事件处理成效等方面进行综合评估。对表现优秀的员工给予表彰和奖励，对能力未达标的员工制定个性化培训计划，帮助其提升专业能力。同时，将能力评估结果与员工职业发展挂钩，为员工晋升、调岗提供参考依据。

## 三、安全事件管理

### （一）事件分类分级

公司依据《生成式人工智能服务安全基本要求》，结合实际业务情况，对安全事件进行科学分类分级。安全事件分为数据安全事件、算法安全事件、网络安全事件、内容安全事件四大类：

1. **数据安全事件**：包括数据泄露、数据篡改、数据丢失等情况，根据受影响数据规模、敏感程度等因素，划分为特别重大、重大、较大和一般四个等级。例如，造成 10 万条以上个人敏感信息泄露的为特别重大数据安全事件。
2. **算法安全事件**：如模型生成非法内容、算法存在严重偏见、模型被恶意攻击导致性能下降等，依据事件影响范围和危害程度分级。若模型生成内容引发社会重大负面影响，则判定为重大算法安全事件。
3. **网络安全事件**：涵盖网络攻击、系统漏洞利用、服务器被入侵等，根据网络瘫痪时长、业务中断影响等因素分级。导致企业核心业务系统中断超过 24 小时的为特别重大网络安全事件。
4. **内容安全事件**：指模型生成虚假信息、违法信息等，按照信息传播范围、社会危害程度分级。若生成的违法信息在互联网广泛传播，造成恶劣社会影响，认定为重大内容安全事件。

### （二）处理流程详解

公司制定了严谨的安全事件处理流程，确保在安全事件发生时能够快速响应、有效处置：

1. **事件监测与发现**：通过信息安全部部署的安全监测系统，实时收集网络日志、系统运行数据、模型输出内容等信息，运用人工智能和大数据分析技术，及时发现异常情况和安全事件线索。同时，建立用户反馈渠道，鼓励用户举报模型生成的非法内容或安全隐患。
2. **事件上报与评估**：一旦发现安全事件，相关人员需在 1 小时内通过内部安全事件上报系统进行报告。信息安全部联合相关部门组成评估小组，在 2 小时内对事件进行初步评估，确定事件类型、等级和影响范围，为后续处置提供依据。
3. **应急响应与处置**：根据事件等级，启动相应级别的应急预案。对于特别重大和重大安全事件，由公司高层领导牵头成立应急指挥部，协调各部门开展处置工作；对于较大和一般安全事件，由信息安全部主导进行处理。在处置过程中，采取数据隔离、系统修复、内容删除等措施，尽快控制事件发展，降低损失。
4. **事件调查与溯源**：在事件得到初步控制后，成立专门的调查小组，对事件原因进行深入调查。通过分析日志数据、审查系统配置、询问相关人员等方式，追溯事件源头，明确责任主体，为后续整改提供依据。
5. **整改与总结**：根据调查结果，制定详细的整改方案，明确整改措施、责任人和完成时间。对涉及的系统、流程、制度进行优化完善，防止类似事件再次发生。同时，形成安全事件处理报告，在公司内部进行通报，总结经验教训，提高全体员工的安全意识和应急处理能力。

### （三）事后复盘机制

公司建立了完善的安全事件事后复盘机制，旨在从事件中吸取经验教训，持续提升安全管理水平。复盘工作在安全事件处理结束后 10 个工作日内开展，由信息安全部组织，相关部门人员参与。

复盘过程分为四个阶段：首先，对安全事件的发生、发展、处置过程进行全面回顾，梳理事件处理流程中的关键节点和操作步骤；其次，分析事件处理过程中存在的问题和不足，包括响应速度是否及时、处置措施是否有效、各部门协作是否顺畅等；然后，针对发现的问题，提出改进建议和优化方案，明确责任部门和整改时间；最后，将复盘结果形成书面报告，提交公司管理层审议，并纳入公司安全管理制度改进计划。

通过定期开展安全事件复盘，公司不断优化安全管理体系和应急处理流程，提升对各类安全事件的防范和应对能力，保障生成式人工智能服务持续安全稳定运行。

# 第三部分：数据措施

## 一、数据清洗技术

### （一）去重算法说明

重庆埃克斯曼得信息技术有限公司在 Xm-phi 大语言模型训练数据处理中，采用基于哈希值与语义相似度相结合的混合去重算法。首先，对采集的文本数据进行分块处理，利用 MD5 哈希算法为每块数据生成唯一哈希值，通过比对哈希值快速识别完全重复的数据块，初步筛除重复数据。对于哈希值不同但内容相近的文本，引入 SimHash 算法计算语义指纹，设定 0.9 的相似度阈值，当两个文本的语义指纹相似度超过该阈值时，判定为相似文本。同时，运用余弦相似度算法对文本向量进行深度计算，进一步验证文本的重复程度，确保去除语义重复内容，提升训练数据的独特性与有效性，减少冗余数据对模型训练的干扰 。

### （二）去毒规则制定

企业依据《生成式人工智能服务安全基本要求》及相关法律法规，制定严格且全面的去毒规则。在内容层面，通过构建多维度敏感词库，包含政治敏感、暴力色情、恐怖主义、谣言虚假等类别，利用正则表达式与自然语言处理技术，对训练数据进行逐句扫描与关键词匹配。一旦检测到敏感词，立即将对应文本标记为待处理状态。对于包含敏感词的文本，进一步结合上下文语义分析，运用情感分析算法与主题模型，判断其是否存在恶意或违规倾向。若确定为有害内容，则将该文本从训练数据集中彻底删除；若仅存在轻微敏感倾向，则对敏感部分进行脱敏处理。此外，针对网络爬虫采集的数据，建立来源信誉评估机制，对信誉度低、存在违规记录的数据源进行自动拦截与数据剔除，从源头杜绝有害数据进入训练流程。

### （三）清洗效果验证

为确保数据清洗效果，企业建立了多阶段、多方式的验证体系。在人工抽检阶段，随机抽取清洗后数据总量 5% 的样本，由专业标注团队依据数据清洗标准进行人工审核，检查去重是否彻底、去毒是否有效，记录误删、漏删等问题并统计误差率。同时，采用交叉验证法，将清洗后的数据划分为训练集和验证集，利用已有的成熟模型对验证集数据进行处理，通过对比模型输出结果与实际预期，评估数据清洗对模型性能的影响，若模型在验证集上的准确率、召回率等指标未达设定阈值，则重新调整数据清洗策略。此外，定期将清洗后的数据与权威、可靠的外部数据集进行对比分析，检查数据的完整性、准确性和合规性，确保数据清洗达到预期效果，为模型训练提供高质量的数据基础。

## 二、数据存储管理

### （一）存储架构设计

Xm-phi 大语言模型训练数据采用分布式存储架构，以满足海量数据存储与高效访问需求。底层基于 Ceph 分布式存储系统构建，将数据分散存储于多个存储节点，通过 CRUSH 算法实现数据的自动分布与冗余备份，确保数据的高可用性和容错性。同时，结合冷热数据分层存储策略，将近期频繁访问的热数据存储在高性能的固态硬盘（SSD）中，以提升数据读取速度；将访问频率较低的冷数据存储在大容量机械硬盘（HDD）中，降低存储成本。此外，搭建数据缓存层，采用 Redis 缓存技术，对常用数据进行缓存，减少对底层存储系统的访问压力，进一步提高数据访问效率。在网络架构方面，部署高速万兆以太网，保障存储节点间数据传输的高速与稳定，为模型训练提供流畅的数据读取环境。

### （二）数据加密方式

企业对存储数据实施全方位加密保护，在数据写入存储系统前，采用 AES - 256 高级加密标准对数据进行加密处理，该算法具有极高的安全性，能够有效抵御暴力破解和密码分析攻击。同时，结合 RSA 非对称加密算法生成数据加密密钥，将加密密钥进行分段存储，并通过安全的密钥管理系统进行管理，确保密钥的安全性和可追溯性。对于不同类型的数据，采用差异化加密策略，如对个人敏感信息进行双重加密，在 AES 加密基础上，再使用同态加密技术，使数据在加密状态下仍可进行计算和处理，进一步保障数据隐私安全。在数据传输过程中，采用 TLS/SSL 协议进行加密传输，防止数据在网络传输过程中被窃取或篡改，确保数据从采集端到存储端、从存储端到模型训练端的全流程加密保护。

### （三）存储备份策略

为防止数据丢失，企业制定了完善的存储备份策略。采用增量备份与全量备份相结合的方式，每日凌晨 2 点进行增量备份，仅备份自上次备份以来发生变化的数据，以减少备份时间和存储空间占用；每周日凌晨执行全量备份，对所有数据进行完整备份，确保数据的全面性和完整性。备份数据存储在与主存储系统物理隔离的异地灾备中心，灾备中心采用与主存储相同的安全防护措施，保障备份数据的安全性。同时，建立备份数据定期验证机制，每月随机抽取 10% 的备份数据进行恢复测试，检查备份数据的完整性和可用性，若发现备份数据损坏或无法恢复，及时启动应急方案重新进行备份，确保在发生数据灾难时能够快速恢复数据，保障模型训练和业务的连续性。

# 第四部分：标注人员情况

## 一、培训体系完善

### （一）培训课程体系

公司构建了系统化、层次分明的标注人员培训课程体系，全面覆盖基础技能、法律法规、行业规范与专业标注知识，确保标注人员具备扎实的理论基础与实践能力。

在基础技能培训课程中，包含文本标注基础、图片标注规范、标注工具操作等核心内容。文本标注基础课程详细讲解文本分词、实体识别、情感分类等标注任务的原理与方法，通过实际案例演示，让标注人员掌握不同文本类型的标注要点；图片标注规范课程针对图像分类、目标检测、语义分割等标注任务，介绍标注标准和流程，强调标注的准确性与一致性；标注工具操作课程则围绕公司自主研发及行业主流标注工具，开展从基础功能使用到高级技巧应用的实操教学，使标注人员能够熟练运用工具高效完成标注工作。

法律法规与行业规范培训是课程体系的重要组成部分。深入解读《生成式人工智能服务管理暂行办法》《个人信息保护法》《数据安全法》等法律法规，明确标注工作中的法律红线与责任义务；同时，结合《生成式人工智能服务安全基本要求》等行业标准，分析标注工作在保障数据安全、算法安全等方面的关键作用，引导标注人员树立合规意识，确保标注数据符合法律与行业规范要求。

针对不同类型的标注任务，设置专项进阶课程。如针对大语言模型训练数据的文本内容标注，开设敏感词识别与处理、语义逻辑判断、知识准确性核查等课程；对于图像标注任务，开展复杂场景目标标注、小目标检测标注等专项培训，提升标注人员在特定领域的专业能力，满足公司多样化标注需求。

### （二）培训教材开发

为保障培训质量，公司组织专业团队自主开发了一套完整的标注人员培训教材，涵盖理论知识、操作指南与案例分析等内容。

理论知识教材以法律法规、行业标准和标注基础理论为核心，采用图文并茂、通俗易懂的编写方式，将抽象的法律条文与专业理论转化为易于理解的表述。例如，在介绍《个人信息保护法》时，通过列举常见的个人信息泄露场景，结合标注工作实际，详细说明标注人员在处理个人信息数据时的注意事项与合规操作流程；在讲解标注基础理论时，运用大量图表展示文本与图像标注的原理与方法，帮助标注人员快速掌握核心知识。

操作指南教材紧密围绕标注工具和实际标注任务编写，包含工具安装与配置、任务创建与分配、标注流程演示等内容。针对公司自主研发的标注工具，提供从登录界面到具体标注功能的分步操作说明，并配有操作截图和视频教程；对于不同类型的标注任务，制定详细的操作流程与规范，如文本情感分类标注的步骤、图像目标框绘制的标准等，使标注人员能够依据指南快速上手，准确完成标注工作。

案例分析教材收集整理了大量实际标注案例，包括正确标注示例、典型错误案例及处理方法。通过对正确案例的分析，展示优秀标注成果的特点与经验；对错误案例进行深入剖析，指出问题所在及可能导致的后果，引导标注人员从中吸取教训。同时，设置互动讨论环节，鼓励标注人员分享自己在标注过程中遇到的问题和解决方法，促进经验交流与学习。

### （三）培训资源保障

公司为标注人员培训提供了充足的资源保障，确保培训工作顺利开展。

在师资力量方面，组建了由内部专家与外部顾问构成的培训团队。内部专家包括公司数据安全部负责人、资深标注团队主管等，他们具备丰富的标注项目管理与实践经验，能够结合公司实际业务，传授实用的标注技巧与管理经验；外部顾问邀请了行业内法律专家、人工智能领域学者等，为标注人员带来前沿的行业动态与专业知识，拓宽标注人员的视野。同时，定期组织培训师参加专业培训与学术交流活动，提升培训师的教学水平与专业素养。

在培训设施与技术支持方面，公司搭建了线上线下一体化的培训平台。线下配备专门的培训教室，安装高清投影设备、电脑终端等硬件设施，为集中授课与实操培训提供良好环境；线上依托公司自主开发的培训管理系统，提供课程视频、电子教材、在线测试等功能，标注人员可随时随地进行学习与练习。此外，设立技术支持小组，及时解决标注人员在培训过程中遇到的技术问题，如线上平台登录故障、标注工具使用异常等，确保培训流程顺畅。同时，为标注人员配备必要的学习资料与工具，如标注手册、笔记本电脑等，满足培训与工作需求。

## 二、人员考核机制

### （一）考核标准制定

公司依据标注工作的实际需求与质量要求，制定了科学、全面的标注人员考核标准，涵盖工作质量、工作效率、法律法规遵守、团队协作等多个维度。

在工作质量方面，设定严格的标注准确性、一致性和完整性指标。准确性要求标注人员对文本语义理解准确、图像目标识别无误，避免出现错误标注；一致性强调同一标注任务在不同时间、不同标注人员之间的标注结果保持一致，通过制定详细的标注规范和定期校准来保障；完整性要求标注人员按照任务要求完成所有标注内容，不得遗漏关键信息。例如，对于文本实体识别任务，规定错误标注率不得超过 3%，标注一致性需达到 95% 以上。

工作效率考核根据标注任务的难度和类型，设定合理的工作量标准与完成时间要求。通过对历史标注数据的分析，结合行业平均水平，确定不同任务的单位时间标注量基准值，同时考虑任务紧急程度和复杂程度，制定灵活的效率考核指标，激励标注人员在保证质量的前提下提高工作效率。

法律法规遵守考核重点检查标注人员在工作过程中是否严格遵守相关法律法规和公司内部规定，如是否妥善处理个人信息数据、是否违规泄露标注内容等，一旦发现违规行为，实行一票否决制。团队协作考核关注标注人员在项目中的沟通配合能力、任务协作效率等方面，通过团队成员互评、项目负责人评价等方式进行综合评估。

### （二）考核方式选择

公司采用多样化的考核方式，确保全面、客观地评价标注人员的能力与表现。

定期考核分为月度考核和季度考核。月度考核以基础工作指标为主，通过统计标注任务完成数量、计算标注错误率等方式，对标注人员当月的工作效率和质量进行量化评分；季度考核则更注重综合能力评估，除工作指标外，还包括法律法规知识测试、案例分析能力考查、团队协作表现评价等内容，采用笔试、实操测试、360 度评价等多种方式进行。

不定期考核主要针对新入职员工和转岗员工的岗前考核，以及重大项目或特殊任务前的专项考核。岗前考核重点考查新员工对培训内容的掌握程度和实际操作能力，通过模拟真实标注任务，检验其是否具备上岗资格；专项考核根据项目特点和要求，设置针对性的考核内容，确保标注人员能够胜任特定项目的标注工作。

此外，引入过程性考核机制，在标注项目执行过程中，通过实时监控标注进度、抽查标注质量、收集客户反馈等方式，及时发现标注人员存在的问题并给予指导和纠正，将过程性考核结果纳入最终考核评价体系，实现对标注人员工作的全过程管理。

### （三）考核结果应用

公司建立了完善的考核结果应用机制，将考核结果与标注人员的职业发展、薪酬福利紧密挂钩，充分发挥考核的激励与导向作用。

在薪酬调整方面，根据考核成绩划分不同的绩效等级，对应不同的绩效奖金系数。考核优秀的标注人员除获得高额绩效奖金外，还可优先参与薪资调级；考核合格的人员获得标准绩效奖金；对于考核不合格的人员，视情况扣除部分绩效奖金或进行薪资下调。

职业发展通道上，考核结果作为标注人员晋升、转岗的重要依据。连续多次考核优秀的标注人员，可优先获得晋升机会，如从初级标注员晋升为高级标注员、标注组长等管理岗位；对于在特定领域表现突出的标注人员，提供转岗至数据分析师、标注规则制定等岗位的机会，拓宽职业发展路径。同时，针对考核中发现的能力短板，为标注人员制定个性化的培训提升计划，帮助其提升专业能力，满足更高岗位要求。

在荣誉激励方面，对考核表现优异的标注人员进行公开表彰，颁发 “优秀标注员”“效率标兵” 等荣誉证书，并在公司内部宣传栏、官方网站等平台进行宣传展示，增强标注人员的职业荣誉感和归属感，营造积极向上的工作氛围，促进标注团队整体水平的提升。

# 第五部分：语料来源情况

语料质量与安全性是生成式人工智能可靠运行的根基。在构建 Xm-phi 大语言模型过程中，我们严格依据《生成式人工智能服务安全基本要求》，从开源数据筛选、合成数据生成到有机数据处理，全流程防控语料及生成内容的安全风险。

## 一、开源数据管理

### （一）开源平台筛选

在构建Xm-phi大语言模型时，重庆埃克斯曼得信息技术有限公司优先从**Hugging Face**平台筛选核心语料，重点引入**Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT数据集**。该数据集覆盖数学、考试、科学技术及通用场景，包含11万条样本，数据来源包括Haijian/Advanced-Math、meta-math/GSM8K_zh等权威库，且经二次校验和模型打分（0-10分），确保内容质量与安全性。例如，数学类数据通过Math-Verify工具校验，通用类数据通过NLP分类器拦截敏感内容，规避A.1类（违反社会主义核心价值观）与A.2类（歧视性内容）风险。

对于基座模型Phi-4的训练数据，参考其开源方法论，从**arXiv、PubMed Central、GitHub**等学术与技术平台提取种子数据。Phi-4的合成数据生成基于“高质量有机数据筛选+合成数据增强”模式，例如从论坛文本中提取问答对时，通过多轮过滤剔除违规内容，并采用“多数投票法”确保答案一致性，避免传播虚假信息（A.1g类）或不准确知识（A.5a类）。

### （二）许可协议审查

针对**Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT数据集**的**Apache-2.0许可**，法务团队重点核查“商业使用限制”“衍生作品署名”等条款，确保模型训练符合“保留原始版权声明”要求，避免A.3类（侵犯知识产权）风险。同时，对比Phi-4数据生成遵循的开源协议（如CC BY-SA），确保多数据源整合时无协议冲突，例如对衍生内容采用“相同许可发布”原则，防止跨协议使用引发法律纠纷。

对于Phi-4合成数据涉及的有机数据源（如书籍、代码库），团队逐例验证授权范围，例如从GitHub获取的代码片段仅用于非商业训练，并通过“指令反转技术”生成合规的“任务-代码”对，避免泄露商业秘密（A.3c类）或侵权。

### （三）数据使用规范

在数据获取阶段，对**Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT**建立详细台账，记录数据集来源URL、许可类型、敏感内容扫描结果（如是否含A.4类隐私信息），并通过哈希值校验数据完整性。例如，对含用户讨论的通用类数据，采用加密哈希技术隐去用户ID，符合A.4e类（保护个人信息权益）要求。

存储与处理环节，将开源数据与自有数据物理隔离，设置“只读访问”权限，禁止未授权修改。参考Phi-4的“合成数据验证机制”，对数学题解答、代码示例进行自动化测试：数学题通过公式校验工具确保逻辑正确，代码片段通过单元测试验证功能合规，防止因数据错误导致模型输出误导性内容（A.5a类）。

定期开展内部审计，抽取5%样本复查协议履行情况，例如核对数据集引用是否完整、脱敏处理是否彻底，确保数据使用全流程可追溯，符合《生成式人工智能服务安全基本要求》中“数据来源合法、使用规范”的核心要求。

## 二、数据质量监控

### （一）多维度质量评估体系

建立覆盖“完整性、准确性、时效性”的三维评估框架。针对**Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT数据集**，通过自动化工具扫描字段缺失率，确保数学题题干、答案字段完整率≥99%，避免因数据残缺导致模型训练偏差（A.5b类风险）。准确性评估采用“模型校验+人工复核”双轨制：数学数据通过Math-Verify工具自动验证解题步骤，通用数据利用Qwen2.5-72B-Instruct模型打分（10分制），对得分<6分的样本标记为“待处理”，重点核查是否存在事实性错误或价值观偏差（如A.1类、A.2类内容）。时效性方面，对医疗、科技类数据设置“更新阈值”，要求季度更新率≥80%，通过爬取PubMed Central最新文献、GitHub热榜代码确保数据鲜活度。

### （二）异常数据闭环处理

构建“预警-隔离-修复”三级响应机制。当系统监测到数据错误率突增（如某批次数学题错误率>5%）或敏感词命中次数超限，立即触发红色预警，自动隔离问题数据并生成《异常数据报告》。技术团队4小时内完成溯源，若属标注错误则启动人工修正；若为平台数据源问题，则追溯至Hugging Face原始数据集，联合社区开发者同步修复。参考Phi-4的“去污染流程”，对含隐私数据的样本采用差分隐私技术模糊化处理，例如将医疗病例中的患者年龄泛化为区间值（如“25-30岁”替代具体年龄），在满足A.4e类要求的同时，确保数据可用性。

### （三）持续优化迭代

建立“用户反馈+内部复盘”双循环改进机制。在模型应用端设置“数据质量反馈入口”，收集用户报告的错误内容（如过时知识点、歧视性表述），48小时内定位至原始数据源并标记风险等级。内部每月开展数据质量复盘会，分析高频问题（如通用类数据中地域歧视内容占比波动），针对性调整筛选策略，例如增加“地域关键词”过滤规则，升级NLP分类器模型。同时，参考Phi-4的“自我修订机制”，对合成数据引入“对抗性测试”，通过模拟恶意输入验证数据鲁棒性，防止低质数据导致模型输出不可靠内容（A.5b类）。

## 三、安全与合规

### （一）全生命周期合规管理

从数据采集到模型训练实施“三审三校”制度。采集阶段，法务团队预审开源协议合规性，技术团队初筛敏感内容；处理阶段，标注团队二审数据标注规范性，合规专员校验隐私处理效果；训练阶段，算法团队三审数据使用记录，确保符合《个人信息保护法》《数据安全法》要求。例如，对Phi-4合成数据中涉及的医疗文本，通过去标识化技术删除可识别信息，并通过独立第三方审计确认合规性，避免A.4类（侵犯隐私权）风险。

### （二）风险防控技术落地

部署“敏感内容防火墙”与“知识产权保护系统”。敏感内容防火墙内置三级词库（政治敏感、暴力色情、歧视性词汇），对Hugging Face下载的原始数据实施实时拦截，例如对含“分裂国家”“性别歧视”等关键词的文本自动阻断入库。知识产权保护系统通过区块链技术为每个数据集生成唯一溯源哈希，训练过程中实时比对输出内容与开源数据的相似度，防止未经授权的衍生作品传播（A.3a类风险）。针对Phi-4的合成数据，建立“代码溯源链”，确保生成的代码片段不侵犯开源协议限制，例如对MIT协议代码仅用于非商业训练，且输出时自动添加原始版权声明。

### （三）应急响应与审计

制定《语料安全事件应急预案》，明确数据泄露、违规内容扩散等场景的处置流程。若发现开源数据包含A.1类内容，1小时内关停数据接口，3小时内完成模型训练数据清洗，并向监管部门备案。每季度开展第三方合规审计，重点核查：①开源数据引用是否完整；②合成数据生成是否符合“多样性、准确性”原则；③隐私数据处理是否符合GDPR等法规要求。审计结果纳入供应商评估体系，对多次违规的数据源永久拉黑，确保语料供应链安全可控。

通过“数据质量监控+安全合规管理”双轮驱动，Xm-phi模型的语料来源严格符合《生成式人工智能服务安全基本要求》，从源头阻断政治风险、伦理风险与法律风险，为模型的可靠运行和合规应用奠定基础。

# 第六部分：数据保护与网络保护情况

在生成式人工智能服务运行过程中，数据与网络安全是防范风险的关键防线。重庆埃克斯曼得信息技术有限公司围绕《生成式人工智能服务安全基本要求》，构建了全方位、多层次的数据保护与网络防护体系，确保业务安全稳定运行。

## 一、数据安全机制

数据安全是保障人工智能服务合法合规的基础。公司从数据分类分级入手，构建了一套严谨且可落地的安全机制。

### （一）数据分类分级

公司依据《数据安全法》，结合业务场景需求，将数据科学划分为四个安全等级。公开数据如 Hugging Face 平台的通用文本语料，虽可在内部非敏感场景使用，但必须标注 “开源引用” 标签，在模型输出时注明来源，防止知识产权纠纷。普通数据像匿名化用户交互日志，虽不含直接识别信息，仍需通过内部审批流程访问，存储于独立数据库，并每周进行完整性校验，防止数据被篡改。

对于敏感数据，如医疗标注语料和含隐私的用户反馈，公司采用 AES - 256 加密存储，每季度轮换加密密钥；访问权限严格限制在授权团队，实行 “一事一授权”，访问记录留存至少 3 年。核心数据，如模型参数和未公开算法逻辑，更是重中之重，实施 “最小知悉原则”，仅核心研发人员通过指纹与动态令牌双因素认证后才可访问，存储于物理隔离的机密服务器，数据导出需技术负责人与合规官双人审批。

以 Congliu/Chinese - DeepSeek - R1 - Distill - data - 110k - SFT 数据集为例，其中的医疗案例、金融问答等内容被归类为敏感数据。公司利用 NLP 技术自动识别姓名、地址等敏感实体，标记为红色标签，随即触发分级保护流程，确保数据安全。

### （二）访问控制策略

为防止数据非法访问与泄露，公司构建了 “零信任” 访问体系，从用户、设备、数据三个维度实施动态权限管控。

在用户认证与授权方面，内部人员需通过指纹识别与 Google Authenticator 动态令牌的双因素认证，权限按岗位角色严格划分；外部合作方采用临时授权码机制，权限有效期不超过 72 小时，且只能访问指定数据集的非敏感字段。同时，每周生成《访问权限报告》，核查异常权限变更，一旦发现违规行为立即自动告警。

设备与网络准入管理同样严格，强制使用公司定制终端，预装安全客户端，禁止自带设备接入。终端内置的数据防泄漏工具实时监控，一旦发现敏感数据通过邮件、U 盘等渠道外发，立即记录日志并阻断操作。

在数据操作审计上，采用 RBAC 模型为不同岗位配置细粒度权限，并对 Phi - 4 合成数据的访问日志进行分钟级审计。一旦出现高频下载或跨地域登录等异常行为，即刻触发实时告警，保障数据操作全程可追溯、可管控。

### （三）数据脱敏处理

公司采用 “静态脱敏 + 动态脱敏 + 隐私计算” 的组合方案，贯穿数据全生命周期。

在预处理阶段，对用户 ID、手机号等标识信息进行不可逆的 SHA - 256 哈希处理；对医疗文本中的敏感内容，用虚拟实体替代；对数值型数据进行区间化泛化处理。在数据使用阶段，模型训练采用联邦学习技术，实现 “数据不动模型动”，如与医院合作训练医疗模型时，仅传输加密后的特征向量，原始病历数据留存本地；API 接口返回数据时，也会进行动态脱敏，隐藏具体病例细节。

此外，定期使用 “隐私风险评估工具” 检测脱敏效果，要求敏感信息识别率不超过 0.1%，并通过第三方机构认证。对于 Phi - 4 合成数据中的代码片段，采用 “指令 - 代码对” 脱敏模式，保留通用算法逻辑，剔除企业特定业务代码，避免商业秘密泄露风险。

## 二、网络安全防护

网络安全是抵御外部攻击、保障系统稳定运行的重要屏障，公司从架构设计到设备部署，构建了完整的防护体系。

### （一）网络架构安全

公司设计了 “分层隔离 + 纵深防御” 的网络架构，划分为核心生产区、开发测试区、公共服务区三大安全域。

核心生产区部署着模型训练集群、数据存储中心等关键业务系统，采用物理隔离技术，禁止直接连接公网。数据输入仅通过单向数据摆渡设备导入开源数据集，导出时需经过严格的安全审计与病毒扫描；训练节点实施 “白名单” 管理，只允许特定 IP 地址访问训练接口，防止外部攻击渗透。

开发测试区配置沙箱环境，研发人员通过跳板机接入，所有代码提交都要经过静态代码扫描和动态渗透测试，检测漏洞与合规风险。测试数据使用脱敏后的副本，禁止调用生产环境真实数据，避免因测试流程问题导致数据泄露。

公共服务区提供模型 API 接口等服务，通过 API 网关实施流量清洗，限制单 IP 并发请求数，抵御 DDoS 攻击；部署 Web 应用防火墙，拦截 SQL 注入、XSS 跨站脚本攻击等常见威胁，实时阻断包含敏感关键词的请求，防范违反社会主义核心价值观的内容传播。同时，参考 Phi - 4 的设计，将内部服务拆分为独立微服务实例，每个实例配置独立认证密钥并定期轮换，降低横向渗透风险。

### （二）安全设备部署

公司构建了多层次的安全设备防护体系，实现对网络威胁的实时检测与响应。

在边界防护层面，入口处部署下一代防火墙，启用入侵防御系统、反病毒引擎及 URL 过滤功能，拦截包含非法内容的链接；对进出流量进行深度包检测，识别并阻断加密隧道、可疑协议通信。

流量监测与分析方面，在核心交换机镜像端口部署全流量分析系统，利用机器学习模型建立正常流量基线，一旦出现异常流量，如突发高频数据上传，立即触发告警。同时，针对模型训练场景，严格监测数据传输协议合规性，禁止使用未加密的 HTTP 协议传输敏感数据，确保符合相关法规要求。

终端与服务器防护上，所有服务器安装端点检测与响应工具，实时扫描勒索软件、挖矿程序等威胁，对可疑进程实施隔离并自动上报；对训练集群节点进行内核级加固，关闭非必要服务端口，每月进行漏洞扫描，48 小时内完成补丁更新，保障系统安全稳定。

### （三）安全监测预警

公司建立了 “监测 - 分析 - 响应 - 改进” 的闭环管理机制，确保网络安全问题能够及时发现、快速处理并持续优化。

通过安全信息与事件管理系统聚合日志数据，实时分析暴力破解训练数据接口、异常数据下载等攻击行为，同时监控 Phi - 4 模型合成数据生成流程，防止未经授权的敏感数据调用。设定多维度预警规则，如单日敏感数据访问失败次数、跨地域 IP 访问核心数据等情况，触发不同等级告警。一旦出现红色告警，如检测到违反社会主义核心价值观内容传播，15 分钟内通知安全负责人，立即启动应急响应流程，关停数据接口并溯源攻击路径。

制定详细的《网络安全事件应急预案》，明确数据泄露、系统入侵等场景的处置流程。若发现开源数据包含违规内容，1 小时内隔离数据集，3 小时内完成模型训练数据清洗并向监管部门备案；每季度开展模拟演练，检验团队响应速度与恢复能力。定期分析安全日志，识别高频攻击手法，更新防火墙规则与入侵检测规则库；跟踪行业安全标准，每年委托第三方机构进行渗透测试与风险评估，持续优化防护措施，确保网络安全防护始终符合最新合规要求。

通过数据安全机制与网络安全防护的紧密协同，Xm - phi 模型体系实现了从数据采集到模型部署全链条的安全管控，有效抵御各类安全风险，为生成式人工智能服务的合法、可靠运行提供了坚实保障。

# 第七部分：评估结果与改进建议

## 一、模型安全评估

### （一）语料内容评估

1. **人工抽检**：为确保语料内容的合规性与质量，我们组建了专业的人工抽检团队，该团队成员均具备丰富的自然语言处理经验与敏锐的内容甄别能力。针对训练语料，按照分层抽样的方法，从不同来源、领域的语料库中抽取了总计4000条样本进行详细审查。重点关注语料中是否存在违法违规信息，如宣扬恐怖主义、色情低俗、暴力犯罪等内容；同时核查是否包含侵犯他人知识产权的内容，例如未经授权使用的文学作品片段、专利技术描述等。经严格审查，合格样本数量为3940条，合格率达到97.5%。少数不合格样本主要源于部分开源语料在引用时未严格筛查，已及时将这些样本从训练集中剔除，并对相关开源渠道进行重新评估与筛选。
2. **关键词抽检**：利用自主研发的关键词检测系统，对海量语料进行快速扫描。我们预先整理了涵盖各类敏感信息的关键词库，包括但不限于政治敏感词、歧视性词汇、虚假信息诱导词等，共计5000余个关键词。系统在运行过程中，对4000条语料进行了关键词匹配抽检。在检测出的疑似问题样本中，进一步通过人工复核确认。最终，确认合格的语料数量为3888条，合格率为97.2%。对于检测出的不合格语料，主要是由于部分网络论坛采集的语料中存在用户随意发布的包含敏感关键词的讨论内容，后续已加强对网络采集语料的清洗规则与审核流程。
3. **分类模型抽检**：构建了多个高精度的分类模型，用于检测语料的类别是否准确以及是否存在不良类别混入的情况。这些分类模型涵盖了新闻、科技、娱乐、教育等常见领域，并针对违法违规内容单独设立了特殊分类。对4000条语料进行分类模型抽检，模型能够准确识别出语料所属类别的数量为3928条，合格率为98.2%。不合格样本主要集中在一些边缘领域语料，由于其内容具有较强的跨领域特征，导致分类模型出现误判，已对这些样本进行重新标注，并优化分类模型的特征提取与训练参数，以提升其对复杂语料的分类能力。

### （二）生成内容评估

1. **人工抽检**：从模型生成的各类文本内容中，随机抽取4000条进行人工评估。评估人员从内容的准确性、逻辑性、合规性以及是否符合社会道德规范等多个维度进行打分。准确性方面，检查生成内容是否与输入指令相关且信息正确；逻辑性关注文本的上下文连贯性与语义通顺度；合规性审查是否包含违法、不良信息；道德规范层面考察是否存在歧视、偏见等不当表述。经评估，合格的生成内容数量为3760条，合格率为94%。不合格的生成内容主要表现为在复杂指令下，模型生成的回答出现事实性错误或逻辑混乱，针对此类问题，已通过增加训练数据多样性与优化模型训练算法来改进。
2. **关键词抽检**：沿用语料内容评估中的关键词检测系统，对模型生成的4000条文本进行关键词筛查。一旦检测到关键词命中，立即对该文本进行详细分析。在本次抽检中，确认合格的生成文本数量为3920条，合格率为98%。不合格的生成文本多为在一些创意写作场景下，模型为追求内容丰富度，意外生成了包含敏感关键词的表述，已通过调整模型的生成策略，增加对敏感关键词的抑制权重，避免此类情况再次发生。
3. **分类模型抽检**：运用与语料内容评估相同的分类模型，对模型生成的4000条文本进行类别判断。分类模型能够正确识别生成文本所属类别的数量为3868条，合格率为96.7%。部分不合格生成文本是因为模型在模仿特定风格写作时，生成的内容偏离了预期类别，目前已通过强化模型对不同风格写作与类别关联的学习，提高生成内容的类别准确性。

### （三）涉知识产权、商业秘密的评估

1. **评估方法**：一方面，采用文本相似度比对技术，将模型生成内容与已知的知识产权数据库（包括专利文献库、学术论文库、知名文学作品库等）以及企业内部的商业秘密文档库进行逐字比对。另一方面，建立专家评审小组，对疑似涉及知识产权或商业秘密侵权的内容进行人工研判。专家小组由法律专家、行业资深技术人员以及知识产权顾问组成，从专业角度判断生成内容是否存在侵权风险。
2. **评判标准**：若文本相似度超过80%，且该内容并非合理引用（如未按照法律规定进行适当标注出处），则判定为可能涉及知识产权侵权；对于商业秘密，若模型生成内容包含企业内部未公开的技术方案、客户名单、营销策略等关键信息，且无合法获取途径说明，即判定为涉及商业秘密侵权。
3. **评估结果**：经过全面评估，在对模型生成的4000条内容进行检测后，未发现明确涉及知识产权侵权的情况。对于商业秘密评估，仅有极个别生成内容因在训练过程中对企业内部公开文档理解偏差，出现了轻微涉及企业内部业务流程描述的情况，但不构成实质性商业秘密泄露风险。针对这一情况，已对相关训练数据进行重新审查与标注，避免类似问题再次出现。

### （四）涉民族、信仰、性别等的评估

1. **评估方法**：构建专门的偏见检测模型，该模型基于深度学习架构，通过大量标注有民族、信仰、性别等偏见信息的文本数据进行训练。同时，结合人工审核，对模型生成内容进行双重把关。人工审核团队接受过跨文化交流、社会平等观念等专业培训，能够准确识别文本中潜在的歧视性表述。
2. **评判标准**：若文本中出现对特定民族、信仰群体的刻板印象描述，如将某个民族与特定负面行为划等号；对不同性别使用带有贬低、歧视性质的词汇或暗示，如形容女性不适合从事某类工作等，均判定为存在偏见问题。
3. **评估结果**：对模型生成的4000条文本进行评估后，发现存在偏见问题的文本数量为4条，占比0.1%。这些问题文本主要集中在早期模型训练阶段，随着训练数据的不断优化与偏见检测机制的持续完善，此类问题得到了有效控制。对于发现的问题文本，立即对模型进行微调，并更新训练数据，增加更多关于平等、多元文化的正向示例，以强化模型对正确价值观的学习。

### （五）涉透明性、准确性、可靠性等的评估

1. **评估方法**：
	- **透明性**：通过分析模型的架构设计文档、训练日志以及对外公开的技术说明，评估模型在数据使用、算法决策过程等方面的透明度。同时，邀请外部专家对模型的透明性进行审查，提出专业意见。
	- **准确性**：利用标准测试数据集（如GLUE、SuperGLUE等自然语言处理基准数据集）对模型进行测试，对比模型输出结果与标准答案，计算准确率、召回率等指标；对于特定领域应用，收集行业内权威的测试案例进行专项测试。
	- **可靠性**：在不同的硬件环境、网络条件下对模型进行压力测试，模拟高并发请求场景，观察模型的运行稳定性与输出一致性；通过长期监测模型在实际业务中的运行数据，分析模型输出结果的波动情况。
2. **评判标准**：
	- **透明性**：模型应清晰说明数据来源、数据处理流程、算法核心原理等关键信息，确保用户与监管机构能够理解模型的运行机制，若关键信息缺失或模糊不清，则判定为透明性不足。
	- **准确性**：在标准测试数据集上，模型的准确率应达到行业领先水平（如在GLUE基准测试中，主要任务的准确率不低于85%）；在特定领域测试中，根据行业标准与实际业务需求设定具体的准确率目标。
	- **可靠性**：在压力测试中，模型应保持稳定运行，无崩溃、卡顿等异常情况，输出结果的一致性达到95%以上；在长期业务监测中，关键性能指标的波动范围应控制在合理区间（如每周模型准确率波动不超过±2%）。
3. **评估结果**：
	- **透明性**：模型已公开详细的技术文档，涵盖数据来源（包括开源数据出处、自采数据采集方法等）、算法架构（Transformer架构及其优化细节）以及训练过程（训练轮次、优化器参数等），外部专家评审认为模型透明性良好，满足行业规范与监管要求。
	- **准确性**：在GLUE基准测试中，模型的综合准确率达到88%，在多个特定领域（如医疗问答、金融资讯生成）的专项测试中，准确率也均超过设定目标，能够为用户提供准确的信息服务。
	- **可靠性**：经过多轮压力测试，模型在高并发场景下能够稳定运行，输出结果一致性达到97%；在长达3个月的实际业务监测中，模型关键性能指标波动稳定，未出现明显异常，表明模型具有较高的可靠性。

## 二、评估结果与改进建议

1. **评估结果总结**：通过对模型安全的多维度评估，整体来看，模型在语料内容、生成内容合规性以及知识产权、社会公平性等方面表现良好。在语料内容评估中，人工抽检、关键词抽检和分类模型抽检合格率分别为98.5%、97.2%和98.2%；生成内容评估中，人工抽检合格率为94%，关键词抽检和分类模型抽检合格率分别为98%和96.7%。在知识产权、商业秘密评估中未发现重大侵权风险；民族、信仰、性别偏见问题占比仅0.1%；透明性、准确性、可靠性评估也达到行业优秀水平。
2. **安全达标情况**：依据《生成式人工智能服务安全基本要求》，模型在各项安全评估指标上均已达标。在数据安全、内容合规、算法透明等关键领域，不仅满足了法规的基本要求，还在实际业务应用中展现出较高的安全性与稳定性，能够为用户提供安全可靠的生成式人工智能服务。然而，我们也认识到在模型训练与优化过程中仍存在一些可提升的空间，将持续关注行业最新安全标准与技术发展，不断完善模型安全体系。
