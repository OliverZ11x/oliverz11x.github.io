---
date created: 2025/5/6 14:52
date modified: 2025/5/29 10:21
---

[长文本提示技巧 - Anthropic](https://docs.anthropic.com/zh-CN/docs/build-with-claude/prompt-engineering/long-context-tips)

[提示工程概述 - Anthropic](https://docs.anthropic.com/zh-CN/docs/build-with-claude/prompt-engineering/overview)

## 通用 Prompt 搭建模板（适用于 AutoGen、GraphRAG 及线上功能）

## 问题

| 问题类别       | 具体表现                                        |
| ---------- | ------------------------------------------- |
| **职责分散**   | 各模块（通用、GraphRAG、AutoGen）由不同人员负责，提示词各自为优化。   |
| **缺乏统一标准** | 没有通用的提示词结构模板、设计原则和格式规范                      |
| **缺少执行标准** | 无提示词版本控制、审查机制或自动追踪流程，哪些提示词应该进行测试，从哪些方面进行优化。 |

## 通用 Prompt 模板统一标准

### 提示词模板分类

- **任务描述类（Task-based Prompts）**：这种提示词明确告诉模型需要执行的任务类型。例如，“生成一段代码”，“翻译成中文”，“提供一个产品推荐”等。
- **指令类（Instruction-based Prompts）**：这种提示词为模型提供具体的指令，指导其如何生成内容。例如，“根据以下条件生成一个故事”，“请用简短的语言总结以下文本”。
- **上下文类（Contextual Prompts）**：这些提示词为模型提供更多的背景或上下文信息，以便更好地理解生成任务。例如，“在此对话中，用户提到了关于天气的讨论，因此，继续与其相关的话题。”
- **反问类（Interrogative Prompts）**：这类提示词包含问题形式，通常用于要求模型回答某个问题或提供相关信息。例如，“如何解决机器学习中的过拟合问题？”。
- **模板类（Template-based Prompts）**：这种提示词给出一定格式或模板，模型需要根据模板填充内容。例如，“填写以下信息：姓名：[姓名]，年龄：[年龄]，职业：[职业]。”
- **自定义类（Custom Prompts）**：根据特定应用需求，用户可以设计非常个性化的提示词，控制模型输出的风格、内容或结构。

### Role-Goal-Prompt

- **精细控制**：通过角色限定和目标定义，可以更精确地控制模型的回答质量。
- **任务清晰**：任务目标明确，减少模型误解任务意图的风险。
- **格式一致**：统一格式要求，便于后续自动化处理和验证。

#### 1. Role (角色)

定义模型在任务中的**身份和能力**，明确模型的功能定位。例如：

- **“You are an expert Social Relationship Analyst.”**
- **“You are a helpful assistant responding to questions about data in the tables provided.”**

**目的**：

- 确保模型采用符合角色的语气和知识背景回答问题。
- 引导模型在回答时关注特定领域或任务，如社交网络分析、医疗诊断或法律咨询。

#### 2. Goal (目标)

描述模型的**任务目标**，包括对输出内容的**总体要求**。通常涉及：

- **任务范围**：明确模型需要生成什么类型的输出，例如报告、摘要或结构化数据。
- **数据引用**：确保模型根据输入数据进行推理，并避免生成未经支持的信息。
- **输出精度**：指导模型在不确定时直接说明“无法回答”，避免“编造”现象。

**例如**：

- **“Write a comprehensive assessment report of a community…”**
- **“Generate a response of the target length and format that responds to the user's question…”**

#### 3. Format (格式)

明确输出的**数据结构和格式**，通常以 JSON、Markdown、表格或自然语言文本形式呈现。例如：

- **JSON 格式**
- **Markdown 标题与段落结构**
- **自然语言回复**

#### 模板字段

| 模板字段                                          | 是否必须 | 描述                      | 示例                                                  |
| --------------------------------------------- | ---- | ----------------------- | --------------------------------------------------- |
| **1. 角色设定（Role Description）**                 | ✅    | 指明 AI/Agent 的职责、身份和能力边界 | “你是一名专业的数据分析助手，擅长根据结构化数据生成自然语言分析报告。”                |
| **2. 任务目标（Task Objective）**                   | ✅    | 明确本次任务的主要目的             | “请根据提供的客户反馈生成一段简洁、具有洞察力的总结性文本。”                     |
| **3. 输入说明（Input Instruction）**                | ✅    | 指明用户/系统将提供的输入格式和内容类型    | “输入为多条客户评价，每条以`-`开头表示。”                             |
| **4. 输出要求（Output Format Requirements）**       | ✅    | 明确输出的格式、风格、长度或结构限制      | “请以 JSON 格式输出，字段包括：summary, sentiment, key_topics。” |
| **5. 行为约束（Behavior Constraints）**             | 可选   | 限制模型的行为范围，防止越权或偏题       | “不要提供解释性说明或假设，请仅基于提供数据输出。”                          |
| **6. 特殊处理逻辑（Fallback or Edge Case Handling）** | 可选   | 指明无输入/输入无效时的处理策略        | “若输入为空，请返回：`{"summary": null}`。”                    |
| **7. 示例**                                     | 可选   | 给出输入输出任务示例              |                                                     |

在构建通用 Prompt 时，尤其是对于任务型模型或大语言模型，结构和字段的设计至关重要。以下是一个通用 **Prompt** 搭建模板所需的核心结构和字段，旨在确保清晰、有效和高效地引导模型完成任务。

### **通用 Prompt 搭建模板**

#### **1. Role (角色)**

- **字段说明**：定义模型在任务中的角色和能力，确保模型根据角色的背景与技能回答问题。
	
- **示例内容**：
	
	- 你是一个社交关系分析专家。
	- 你是一个医学专家，擅长诊断和治疗建议。
	- 你是一个财务顾问，专门帮助用户进行投资规划。

#### **2. Goal (目标)**

- **字段说明**：明确模型需要达成的任务目标。包括任务的范围、输出形式、数据处理要求等。
	
- **示例内容**：
	
	- 根据给定的数据和信息生成详细的分析报告。
	- 给出一个简洁的总结，回答用户的问题。
	- 提供一个具体的推荐方案，并根据已有数据给出依据。

#### **3. Input Instruction (输入说明)**

- **字段说明**：定义模型在生成答案或报告时需要使用的输入数据。可能包含结构化数据（如表格、列表）或非结构化数据（如段落、文档等）。
	
- **示例内容**：
	
	- 数据表、记录集、实体列表、关系图。
	- 文本段落、新闻报道、社交媒体信息等。

#### **4. Constraints (限制条件)**

- **字段说明**：为模型设置一些行为或输出的约束。避免模型产生不相关、错误或不合规的内容。
	
- **示例内容**：
	
	- **不能编造信息**，若无法回答，请直接说明。
	- 输出应在 200 字以内。
	- 仅使用给定数据和背景，不允许引用外部知识。

#### **5. Format (格式要求)**

- **字段说明**：明确输出的格式要求。这有助于确保模型的输出符合预期的结构，便于后续处理。
	
- **示例内容**：
	
	- 输出为 **JSON** 格式，包含指定字段。
	- 输出为 **Markdown** 格式，使用标题、段落和列表结构。
	- 输出为自然语言回答，遵循简洁、专业的语气。

#### **6. Data Reference (数据引用)**

- **字段说明**：确保模型能够基于给定的数据进行推理。要求模型在回答中引用数据来源，确保准确性和透明度。
	
- **示例内容**：
	
	- **数据引用**格式：
		"这是一个示例句子，支持数据引用 [Data: 数据集名 (记录ID); 数据集名 (记录ID)]"
	- 不允许模型引用未提供的数据或外部来源。

#### **8. Example (示例)**

- **字段说明**：提供一个典型的输入和输出示例，以帮助模型理解任务结构和输出格式。
	
- **示例内容**：
	
	- **输入示例**：提供一段输入文本或数据。
	- **输出示例**：给出模型应生成的输出。

![[GraphRAG提示词模板#basic_search_system_prompt]]

---

### **模板设计要点**

1. **清晰的角色设定**：帮助模型明白它的功能和应遵循的行为方式。
2. **目标明确**：确保模型生成的结果能够满足任务要求。
3. **输入数据结构化**：使模型能方便地访问并处理相关数据，确保准确性。
4. **格式要求规范化**：输出格式固定，方便后续处理和验证。

---

## GraphRAG 专项

[[GraphRAG提示词模板优化策略]]

[自动调优 - 图 RAG --- Auto Tuning - GraphRAG](https://microsoft.github.io/graphrag/prompt_tuning/auto_prompt_tuning/)

├── basic_search_system_prompt. Txt

├── community_report_graph. Txt

├── community_report_text. Txt

├── drift_reduce_prompt. Txt

├── drift_search_system_prompt. Txt

├── extract_claims. Txt

├── extract_graph. Txt

├── global_search_knowledge_system_prompt. Txt

├── global_search_map_system_prompt. Txt

├── global_search_reduce_system_prompt. Txt

├── local_search_system_prompt. Txt

├── question_gen_system_prompt. Txt

└── summarize_descriptions. Txt

---

## AutoGen

为 AutoGen 设置统一的提示词制定指标，目的是确保各类 agent 的系统提示（system message/prompt）在任务执行中具备 **清晰目标、强约束性、可追踪性和调优潜力**。

搭配使用 AutoGen 的 [`tracing`](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tracing.html) 工具，将 prompt 与执行链路绑定，记录分析各 Agent 的执行效率和失败原因。

[追踪和可观察性 — AutoGen --- Tracing and Observability — AutoGen](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tracing.html)

| 指标         | 示例                                                |
| ---------- | ------------------------------------------------- |
| 职责定义清晰     | “你是一个执行 agent，仅负责运行用户请求的 Python 代码。”              |
| 拒绝无关任务     | “不要尝试解释代码内容或进行总结。”                                |
| 输入输出结构清晰   | “你的输入是以 Markdown 代码块形式提供的 Python 脚本，输出应为运行结果字符串。” |
| 出错容忍性      | “若代码报错，请以`{"error": "…"}`格式返回”                  |
| tracing 支持 | “你当前处理的是任务ID #T123，由主控 Agent 分派，任务描述为 xxx。”       |

---

## 提示词设计与评估的标准体系建设

### 1. 建立“统一模板与流程”标准文档

|模块|内容|
|---|---|
|Prompt 原文|当前使用的提示词内容|
|使用场景|对应任务（如AI助手问答、GraphRAG结构化问答等）|
|优化目标|例如减少冗余/提高召回率/提升上下文理解|
|优化策略|采用哪种方法（静态设计/PEFT/Agent反思等）|
|优化版本记录|修改人 + 时间 + 简要说明|
|评估方式|使用哪些指标（自动/人工），当前得分|

### 2. 评估方式

#### 人工评估

- **流畅性（Fluency）**：
	- 评估生成文本是否语法正确、语言自然流畅。
- **相关性（Relevance）**：
	- 评估生成的文本是否与输入提示或上下文相关。
- **创造性（Creativity）**：
	- 评估生成文本是否具有新意和创新性，特别是在生成类任务中。
- **一致性（Consistency）**：
	- 评估生成文本是否在逻辑上前后一致，特别是在多轮对话任务中。
- **准确性（Accuracy）**：
	- 评估模型生成的回答是否与事实相符，尤其在问答任务中。
- **可读性（Readability）**：
	- 评估生成的文本是否易于理解，是否符合语言习惯。

#### 语言模型自评估（LLM-as-a-Judge）

使用另一个独立的语言模型作为“评审”角色来评估生成文本的质量。这个评审模型可以给出更精确的反馈，比如：

- **评估生成内容是否符合上下文**：通过评审模型来判断生成的文本是否在给定的情境下合理。
- **分类任务中的准确性评估**：通过判别模型评估生成的答案是否正确。

这种方法通过组合多个语言模型的力量，使得最终的评估结果更加稳定和可靠。

#### 评估指标（数学方法后期考虑）

- **ROUGE（Recall-Oriented Understudy for Gisting Evaluation）**：
	- 主要用于评估摘要生成的质量，特别是召回率。通过计算生成文本和参考文本之间的n-gram重叠来衡量生成质量。
	- 适用于文本摘要、摘要生成等任务。
		
- **METEOR（Metric for Evaluation of Translation with Explicit ORdering）**：
	- 结合了精确度、召回率和同义词匹配等因素，是一个比 BLEU 更全面的评估标准。
	- 适用于多种生成任务。
		
- **MMLU（Massive Multitask Language Understanding）**：
	- 是一个多任务评估基准，评估模型在各种任务（如数学推理、事实性问答等）上的表现。
	- 用于测试大规模多任务的模型生成能力。
		
- **HellaSwag**：
	- 是一个基于上下文生成的评估任务，模型需要选择与给定上下文最匹配的下一句话。
	- 用于评估语言模型的生成能力和常识推理。
		
- **TruthfulQA**：
	- 评估模型是否能够生成准确、真实的答案，特别适用于基于事实的回答生成任务。